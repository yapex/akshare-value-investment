"""
æ™ºèƒ½SQLiteç¼“å­˜è£…é¥°å™¨

ç”Ÿäº§çº§è£…é¥°å™¨å®ç°ï¼Œæ”¯æŒï¼š
1. é€æ˜çš„ç¼“å­˜é›†æˆ
2. æ™ºèƒ½å¢é‡æ›´æ–°
3. å¤šç§æ—¥æœŸå­—æ®µæ”¯æŒ
4. çµæ´»çš„æŸ¥è¯¢ç±»å‹é…ç½®
5. è¯¦ç»†çš„æ—¥å¿—å’Œç›‘æ§
"""

import functools
import logging
from typing import Callable, Any, Optional, List, Dict
from datetime import datetime, timedelta
from .sqlite_cache import SQLiteCache

logger = logging.getLogger(__name__)


def smart_sqlite_cache(
    date_field: str = 'date',
    query_type: str = 'indicators',
    cache_adapter: Optional[SQLiteCache] = None,
    cache_path: str = "cache/financial_data.db",
    enable_logging: bool = True
):
    """
    æ™ºèƒ½SQLiteç¼“å­˜è£…é¥°å™¨

    Args:
        date_field: æ—¥æœŸå­—æ®µåï¼ˆdate/report_date/end_dateï¼‰
        query_type: æŸ¥è¯¢ç±»å‹ï¼ˆindicators/profit/balance/cashflowï¼‰
        cache_adapter: å¤–éƒ¨ç¼“å­˜é€‚é…å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        cache_path: ç¼“å­˜æ•°æ®åº“è·¯å¾„
        enable_logging: æ˜¯å¦å¯ç”¨è¯¦ç»†æ—¥å¿—

    Returns:
        è£…é¥°å¥½çš„å‡½æ•°

    Usage:
        # åŸºç¡€ç”¨æ³•
        @smart_sqlite_cache(date_field='date', query_type='indicators')
        def get_financial_indicators(symbol, start_date, end_date):
            return akshare.stock_financial_indicators(symbol=symbol)

        # è‡ªå®šä¹‰ç¼“å­˜é€‚é…å™¨
        adapter = SQLiteCache("custom/cache.db")
        @smart_sqlite_cache(date_field='report_date', query_type='profit', cache_adapter=adapter)
        def get_profit_statement(symbol, start_date, end_date):
            return akshare.stock_profit_sheet(symbol=symbol)
    """
    def decorator(func: Callable) -> Callable:
        # åˆå§‹åŒ–ç¼“å­˜é€‚é…å™¨
        if cache_adapter is None:
            adapter = SQLiteCache(cache_path)
        else:
            adapter = cache_adapter

        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            # å‚æ•°è§£æ - æœŸæœ›(symbol, start_date, end_date) æˆ–å…³é”®å­—å‚æ•°
            symbol, start_date, end_date = _parse_function_args(func, args, kwargs)

            if enable_logging:
                logger.debug(f"ğŸ” æŸ¥è¯¢ {symbol} {query_type} {start_date} åˆ° {end_date}")

            # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦å¢é‡æ›´æ–°
            missing_ranges = adapter._get_missing_date_ranges(
                symbol=symbol,
                start_date=start_date,
                end_date=end_date,
                date_field=date_field,
                query_type=query_type
            )

            # è·å–ç¼“å­˜è¦†ç›–æƒ…å†µï¼Œç”¨äºè¯¦ç»†æ—¥å¿—
            if enable_logging:
                if not missing_ranges:
                    # å®Œå…¨ç¼“å­˜å‘½ä¸­
                    logger.debug(f"âœ… ç¼“å­˜å®Œå…¨å‘½ä¸­")
                    # è¿”å›å·²ç¼“å­˜çš„å®Œæ•´æ•°æ®
                    cached_results = adapter.query_by_date_range(
                        symbol, start_date, end_date, date_field, query_type
                    )
                    import pandas as pd
                    return pd.DataFrame(cached_results)
                else:
                    # æœ‰ç¼“å­˜ç¼ºå¤±ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦å¢é‡è¡¥å……
                    is_incremental = len(missing_ranges) == 1 and (
                        (missing_ranges[0]['start'] == start_date and missing_ranges[0]['end'] != end_date) or
                        (missing_ranges[0]['start'] != start_date and missing_ranges[0]['end'] == end_date)
                    )
                    if is_incremental:
                        logger.debug(f"ğŸ”„ æ£€æµ‹åˆ°å•è¾¹ç¼ºå¤±ï¼Œå°†æŒ‰éœ€å¢é‡è¡¥å……")
                    else:
                        logger.debug(f"ğŸ”„ æ£€æµ‹åˆ°å¤šè¾¹ç¼ºå¤±ï¼Œå°†é‡æ–°è·å–å®Œæ•´æ•°æ®")

            # 3. æ ¹æ®ç¼ºå¤±èŒƒå›´è°ƒç”¨åŸå‡½æ•°
            if not missing_ranges:
                # å®Œå…¨ç¼“å­˜å‘½ä¸­ï¼Œåœ¨ä¸Šé¢å·²ç»è¿”å›
                pass
            elif len(missing_ranges) == 1 and (missing_ranges[0]['start'] != start_date or missing_ranges[0]['end'] != end_date):
                # å¢é‡æ›´æ–°ï¼šåªè·å–ç¼ºå¤±éƒ¨åˆ†
                missing_range = missing_ranges[0]
                logger.debug(f"ğŸ“¡ å¢é‡è·å–ç¼ºå¤±æ•°æ®: {missing_range['start']} åˆ° {missing_range['end']}")

                # è°ƒç”¨åŸå‡½æ•°è·å–ç¼ºå¤±æ•°æ®
                import inspect
                sig = inspect.signature(func)
                bound_args = sig.bind_partial(*args, **kwargs)
                bound_args.apply_defaults()

                # æ›´æ–°æ—¥æœŸå‚æ•°ä¸ºç¼ºå¤±èŒƒå›´
                if 'start_date' in bound_args.arguments:
                    bound_args.arguments['start_date'] = missing_range['start']
                if 'end_date' in bound_args.arguments:
                    bound_args.arguments['end_date'] = missing_range['end']

                api_results = func(*bound_args.args, **bound_args.kwargs)

                # è·å–ç°æœ‰ç¼“å­˜æ•°æ®å¹¶åˆå¹¶
                if api_results is not None:
                    # å®‰å…¨çš„DataFrameç©ºå€¼æ£€æŸ¥
                    import pandas as pd
                    if hasattr(api_results, 'empty') and not api_results.empty:
                        saved_count = adapter.save_records(
                            symbol=symbol,
                            records=api_results,
                            date_field=date_field,
                            query_type=query_type
                        )
                        # ä¿å­˜è®°å½•çš„æ—¥å¿—å·²åœ¨sqlite_cache.pyä¸­å¤„ç†ï¼Œè¿™é‡Œä¸å†é‡å¤

                # è¿”å›å®Œæ•´èŒƒå›´çš„åˆå¹¶æ•°æ®
                cached_results = adapter.query_by_date_range(
                    symbol, start_date, end_date, date_field, query_type
                )
                import pandas as pd
                return pd.DataFrame(cached_results)
            else:
                # å®Œæ•´é‡æ–°è·å–
                logger.debug(f"ğŸ“¡ å®Œæ•´è·å–æ•°æ®: {start_date} åˆ° {end_date}")
                api_results = func(*args, **kwargs)

            if api_results is None or (hasattr(api_results, 'empty') and api_results.empty):
                if enable_logging:
                    logger.warning(f"âš ï¸ APIè¿”å›ç©ºæ•°æ®: {symbol}")
                return []

            # 4. ä¿å­˜åˆ°ç¼“å­˜
            saved_count = adapter.save_records(
                symbol=symbol,
                records=api_results,
                date_field=date_field,
                query_type=query_type
            )

            # ä¿å­˜è®°å½•çš„æ—¥å¿—å·²åœ¨sqlite_cache.pyä¸­å¤„ç†ï¼Œè¿™é‡Œä¸å†é‡å¤

            return api_results

        # æ·»åŠ ç¼“å­˜ç®¡ç†æ–¹æ³•åˆ°åŒ…è£…å‡½æ•°
        wrapper.cache_adapter = adapter

        return wrapper

    return decorator


def _parse_function_args(func: Callable, args: tuple, kwargs: dict) -> tuple:
    """
    è§£æå‡½æ•°å‚æ•°ï¼Œæå–(symbol, start_date, end_date)

    æ”¯æŒå¤šç§è°ƒç”¨æ–¹å¼ï¼š
    1. ä½ç½®å‚æ•°ï¼šfunc(symbol, start_date, end_date)
    2. å…³é”®å­—å‚æ•°ï¼šfunc(symbol="SH600519", start_date="2023-01-01", end_date="2023-12-31")
    3. æ··åˆå‚æ•°ï¼šfunc("SH600519", start_date="2023-01-01", end_date="2023-12-31")
    """
    import inspect

    sig = inspect.signature(func)
    bound_args = sig.bind_partial(*args, **kwargs)
    bound_args.apply_defaults()

    # å°è¯•å¤šç§å¸¸è§çš„å‚æ•°å
    param_names = ['symbol', 'start_date', 'end_date', 'symbol_code', 'begin_date', 'finish_date']

    result = []
    for expected_name in ['symbol', 'start_date', 'end_date']:
        value = None

        # 1. é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…
        if expected_name in bound_args.arguments:
            value = bound_args.arguments[expected_name]
        else:
            # 2. å°è¯•æ¨¡ç³ŠåŒ¹é…
            for param_name, param_value in bound_args.arguments.items():
                if expected_name in param_name.lower() or param_name.lower() in expected_name:
                    value = param_value
                    break

        if value is None:
            raise ValueError(f"æ— æ³•æ‰¾åˆ°å‚æ•°: {expected_name}. å¯ç”¨å‚æ•°: {list(bound_args.arguments.keys())}")

        result.append(value)

    return tuple(result)


class CacheManager:
    """
    ç®€åŒ–çš„ç¼“å­˜ç®¡ç†å™¨ - æä¾›åŸºæœ¬çš„ç¼“å­˜ç»Ÿè®¡å’Œæ¸…ç†åŠŸèƒ½
    """

    def __init__(self, cache_path: str = "cache/financial_data.db"):
        self.adapter = SQLiteCache(cache_path)

    def get_global_stats(self) -> dict:
        """è·å–å…¨å±€ç¼“å­˜ç»Ÿè®¡"""
        cache_stats = self.adapter.get_cache_stats()

        return {
            'total_records': cache_stats.total_records,
            'total_queries': cache_stats.total_queries,
            'cache_hits': cache_stats.cache_hits,
            'cache_misses': cache_stats.cache_misses,
            'cache_hit_rate': f"{cache_stats.cache_hit_rate:.2%}"
        }

    def get_all_symbols_summary(self) -> Dict[str, Dict]:
        """è·å–æ‰€æœ‰è‚¡ç¥¨çš„ç¼“å­˜æ¦‚è¦"""
        conn = self.adapter._get_connection()
        cursor = conn.cursor()

        cursor.execute("""
            SELECT DISTINCT symbol FROM financial_data ORDER BY symbol
        """)

        symbols = list(row[0] for row in cursor.fetchall())
        return symbols

    def close(self) -> None:
        """å…³é—­ç¼“å­˜ç®¡ç†å™¨"""
        self.adapter.close()


# å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
_global_cache_manager = None


def get_cache_manager() -> CacheManager:
    """è·å–å…¨å±€ç¼“å­˜ç®¡ç†å™¨"""
    global _global_cache_manager
    if _global_cache_manager is None:
        _global_cache_manager = CacheManager()
    return _global_cache_manager