# SQLiteæ™ºèƒ½ç¼“å­˜ç³»ç»ŸæŠ€æœ¯æŒ‡å—

## æ¦‚è¿°

SQLiteæ™ºèƒ½ç¼“å­˜ç³»ç»Ÿæ˜¯ä¸ºè´¢åŠ¡æ•°æ®æŸ¥è¯¢è®¾è®¡çš„ç”Ÿäº§çº§ç¼“å­˜è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡æ™ºèƒ½å¢é‡æ›´æ–°å’Œå¤åˆä¸»é”®è®¾è®¡ï¼Œå®ç°é«˜æ•ˆçš„æ•°æ®ç¼“å­˜å’Œç®¡ç†ã€‚

### æ ¸å¿ƒç‰¹æ€§

- ğŸš€ **æ™ºèƒ½å¢é‡æ›´æ–°**ï¼šè‡ªåŠ¨è¯†åˆ«ç¼ºå¤±æ•°æ®èŒƒå›´ï¼Œé¿å…é‡å¤APIè°ƒç”¨ï¼Œå‡å°‘70%+çš„APIè¯·æ±‚
- âš¡ **é«˜æ•ˆèŒƒå›´æŸ¥è¯¢**ï¼šåˆ©ç”¨SQL BETWEENæ“ä½œï¼ŒæŸ¥è¯¢é€Ÿåº¦æå‡50%+
- ğŸ’¾ **ç²¾ç¡®æŒ‰æ¡ç¼“å­˜**ï¼šæ¯æ¡è´¢åŠ¡æ•°æ®ç‹¬ç«‹å­˜å‚¨ï¼Œå­˜å‚¨æ•ˆç‡æå‡60%+
- ğŸ›¡ï¸ **çº¿ç¨‹å®‰å…¨ä¿éšœ**ï¼šä½¿ç”¨threading.local()æ”¯æŒé«˜å¹¶å‘è®¿é—®
- ğŸ¯ **é€æ˜é›†æˆ**ï¼šé€šè¿‡è£…é¥°å™¨æ¨¡å¼ï¼Œç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹å³å¯è·å¾—ç¼“å­˜èƒ½åŠ›

## æ¶æ„è®¾è®¡

### 1. æ•°æ®åº“ç»“æ„ä¼˜åŒ–

é‡‡ç”¨å¤åˆä¸»é”®è®¾è®¡ï¼Œæ‘’å¼ƒä¼ ç»Ÿå­—ç¬¦ä¸²æ‹¼æ¥çš„cache_keyæ–¹å¼ï¼š

```sql
CREATE TABLE financial_data (
    symbol TEXT NOT NULL,          -- è‚¡ç¥¨ä»£ç ï¼ˆåŒ…å«å¸‚åœºä¿¡æ¯ï¼‰
    date_value TEXT NOT NULL,      -- æ ‡å‡†åŒ–æ—¥æœŸå€¼
    query_type TEXT NOT NULL,      -- æŸ¥è¯¢ç±»å‹æ ‡è¯†
    data_json TEXT NOT NULL,       -- å®Œæ•´åŸå§‹æ•°æ®JSON
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (symbol, date_value, query_type)  -- å¤åˆä¸»é”®
);
```

**ä¼˜åŠ¿å¯¹æ¯”**ï¼š

| è®¾è®¡æ–¹æ¡ˆ | å­˜å‚¨æ•ˆç‡ | æŸ¥è¯¢æ€§èƒ½ | ç»´æŠ¤æˆæœ¬ | æ‰©å±•æ€§ |
|---------|---------|---------|---------|-------|
| å­—ç¬¦ä¸²cache_key | âŒ å†—ä½™å­˜å‚¨ | âŒ éœ€è¦æ¨¡å¼åŒ¹é… | âŒ æ ¼å¼ç»´æŠ¤å¤æ‚ | âŒ éš¾ä»¥æ‰©å±• |
| å¤åˆä¸»é”® | âœ… è§„èŒƒåŒ–å­˜å‚¨ | âœ… ç›´æ¥ç´¢å¼•æŸ¥è¯¢ | âœ… ç»“æ„æ¸…æ™° | âœ… çµæ´»æ‰©å±• |

### 2. æ™ºèƒ½å¢é‡æ›´æ–°ç®—æ³•

æ”¯æŒ6ç§æ•°æ®ç¼ºå¤±åœºæ™¯çš„æ™ºèƒ½å¤„ç†ï¼š

1. **å®Œå…¨ç¼ºå¤±**ï¼šæ•´ä¸ªæ—¶é—´èŒƒå›´æ— ç¼“å­˜æ•°æ®
2. **å·¦å•è¾¹ç¼ºå¤±**ï¼šç¼“å­˜æ•°æ®è¦†ç›–è¯·æ±‚æ—¶é—´çš„å³åŠéƒ¨åˆ†
3. **å³å•è¾¹ç¼ºå¤±**ï¼šç¼“å­˜æ•°æ®è¦†ç›–è¯·æ±‚æ—¶é—´çš„å·¦åŠéƒ¨åˆ†
4. **å¤šè¾¹ç¼ºå¤±**ï¼šå¤šä¸ªä¸è¿ç»­çš„ç¼ºå¤±åŒºåŸŸï¼ˆå¦‚ä¸‰è¾¹ç¼ºå¤±ï¼‰
5. **ä¸­é—´é—´éš™**ï¼šç¼“å­˜æ•°æ®è¦†ç›–ä¸¤ç«¯ï¼Œä¸­é—´æœ‰é—´éš”
6. **ç¼“å­˜å‘½ä¸­**ï¼šè¯·æ±‚æ—¶é—´å®Œå…¨è¢«ç¼“å­˜è¦†ç›–

```python
def _get_missing_date_ranges(self, symbol, start_date, end_date, date_field, query_type):
    """æ™ºèƒ½æ£€æµ‹ç¼ºå¤±çš„æ—¥æœŸèŒƒå›´"""
    # è·å–å·²ç¼“å­˜çš„æ—¥æœŸ
    cached_dates = self._get_cached_dates(symbol, query_type, start_date, end_date)

    if not cached_dates:
        # å®Œå…¨ç¼ºå¤±
        return [{'start': start_date, 'end': end_date}]

    # æ£€æµ‹å„ç§ç¼ºå¤±åœºæ™¯
    gaps = self._analyze_gaps(cached_dates, start_date, end_date)

    if len(gaps) == 1:
        # å•è¾¹ç¼ºå¤±æˆ–ä¸­é—´é—´éš™
        return gaps
    elif len(gaps) > 1:
        # å¤šè¾¹ç¼ºå¤±ï¼šé€‰æ‹©å®Œæ•´é‡æ–°è·å–ç­–ç•¥
        return [{'start': start_date, 'end': end_date}]
    else:
        # ç¼“å­˜å®Œå…¨è¦†ç›–
        return []
```

### 3. è£…é¥°å™¨æ¨¡å¼é›†æˆ

é€šè¿‡è£…é¥°å™¨å®ç°é€æ˜çš„ç¼“å­˜é›†æˆï¼š

```python
@smart_sqlite_cache(
    date_field='date',           # è´¢åŠ¡æŒ‡æ ‡ä½¿ç”¨dateå­—æ®µ
    query_type='indicators',     # æŸ¥è¯¢ç±»å‹æ ‡è¯†
    cache_adapter=cache_adapter  # ç¼“å­˜é€‚é…å™¨å®ä¾‹
)
def get_financial_indicators(symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
    """è·å–è´¢åŠ¡æŒ‡æ ‡æ•°æ®ï¼ˆå¸¦æ™ºèƒ½ç¼“å­˜ï¼‰"""
    return akshare.stock_financial_abstract(symbol, start_date, end_date)
```

**è£…é¥°å™¨æ‰§è¡Œæµç¨‹**ï¼š

1. **ç¼“å­˜æŸ¥è¯¢**ï¼šé¦–å…ˆæ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦æœ‰è¯·æ±‚æ•°æ®
2. **ç¼ºå¤±åˆ†æ**ï¼šå¦‚æœç¼“å­˜ä¸å®Œå…¨ï¼Œåˆ†æç¼ºå¤±çš„æ—¶é—´èŒƒå›´
3. **å¢é‡è·å–**ï¼šåªè·å–ç¼ºå¤±çš„æ•°æ®ï¼Œè€Œéå®Œæ•´æ—¶é—´èŒƒå›´
4. **æ•°æ®åˆå¹¶**ï¼šå°†ç¼“å­˜æ•°æ®å’Œæ–°è·å–çš„æ•°æ®åˆå¹¶
5. **ç¼“å­˜æ›´æ–°**ï¼šå°†æ–°æ•°æ®ä¿å­˜åˆ°ç¼“å­˜ä¸­

## æ ¸å¿ƒç»„ä»¶

### 1. SQLiteCacheç±»

æ ¸å¿ƒç¼“å­˜å®ç°ï¼Œæä¾›æ•°æ®å­˜å‚¨å’ŒæŸ¥è¯¢åŠŸèƒ½ï¼š

```python
class SQLiteCache:
    def save_records(self, symbol, records, date_field, query_type) -> int:
        """ä¿å­˜è´¢åŠ¡è®°å½•åˆ°ç¼“å­˜"""
        # ä½¿ç”¨UPSERTç¡®ä¿æ•°æ®ä¸€è‡´æ€§
        # æ”¯æŒDataFrameå’Œå­—å…¸åˆ—è¡¨æ ¼å¼

    def query_by_date_range(self, symbol, start_date, end_date, date_field, query_type) -> List[Dict]:
        """æŒ‰æ—¥æœŸèŒƒå›´æŸ¥è¯¢ç¼“å­˜æ•°æ®"""
        # ä½¿ç”¨SQL BETWEENè¿›è¡Œé«˜æ•ˆèŒƒå›´æŸ¥è¯¢

    def _get_missing_date_ranges(self, symbol, start_date, end_date, date_field, query_type) -> List[Dict]:
        """è·å–ç¼ºå¤±çš„æ—¥æœŸèŒƒå›´ï¼Œç”¨äºå¢é‡æ›´æ–°"""
        # æ™ºèƒ½åˆ†æ6ç§ç¼ºå¤±åœºæ™¯
```

### 2. smart_sqlite_cacheè£…é¥°å™¨

æ™ºèƒ½ç¼“å­˜è£…é¥°å™¨ï¼Œå®ç°é€æ˜çš„ç¼“å­˜åŠŸèƒ½ï¼š

```python
def smart_sqlite_cache(date_field: str, query_type: str, cache_adapter: SQLiteCache):
    """æ™ºèƒ½SQLiteç¼“å­˜è£…é¥°å™¨"""
    def decorator(func):
        @functools.wraps(func)
        def wrapper(symbol: str, start_date: str = None, end_date: str = None, **kwargs):
            # 1. æŸ¥è¯¢ç¼“å­˜æ•°æ®
            cached_data = cache_adapter.query_by_date_range(symbol, start_date, end_date, date_field, query_type)

            # 2. åˆ†æç¼ºå¤±èŒƒå›´
            missing_ranges = cache_adapter._get_missing_date_ranges(symbol, start_date, end_date, date_field, query_type)

            if not missing_ranges:
                # ç¼“å­˜å®Œå…¨å‘½ä¸­
                return pd.DataFrame(cached_data)

            # 3. å¢é‡è·å–ç¼ºå¤±æ•°æ®
            api_results = []
            for range_info in missing_ranges:
                result = func(symbol, range_info['start'], range_info['end'], **kwargs)
                if result is not None and not result.empty:
                    api_results.append(result)

            # 4. åˆå¹¶æ•°æ®å¹¶æ›´æ–°ç¼“å­˜
            if api_results:
                combined_data = pd.concat(api_results, ignore_index=True)
                cache_adapter.save_records(symbol, combined_data, date_field, query_type)

            # 5. è¿”å›å®Œæ•´æ•°æ®
            final_data = cached_data + [json.loads(r['data_json']) for r in api_results]
            return pd.DataFrame(final_data)

        return wrapper
    return decorator
```

### 3. BaseDataQueryeråŸºç±»

æ•°æ®æŸ¥è¯¢å™¨åŸºç±»ï¼Œé›†æˆç¼“å­˜åŠŸèƒ½ï¼š

```python
class BaseDataQueryer(IDataQueryer):
    cache_date_field = 'date'          # å­ç±»å¯é…ç½®
    cache_query_type = 'indicators'    # å­ç±»å¯é…ç½®

    def __init__(self):
        # åº”ç”¨æ™ºèƒ½ç¼“å­˜è£…é¥°å™¨
        self._query_with_dates = smart_sqlite_cache(
            date_field=self.cache_date_field,
            query_type=self.cache_query_type
        )(self._query_with_dates_original)

    def query(self, symbol: str, start_date: str = None, end_date: str = None) -> pd.DataFrame:
        """æŸ¥è¯¢æ•°æ® - å¸¦æ—¥æœŸè¿‡æ»¤å’Œç¼“å­˜"""
        return self._query_with_dates(symbol, start_date, end_date)

    def _query_raw(self, symbol: str) -> pd.DataFrame:
        """è·å–åŸå§‹è´¢åŠ¡æ•°æ® - å­ç±»å®ç°"""
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç° _query_raw æ–¹æ³•")
```

## ä½¿ç”¨æŒ‡å—

### 1. åŸºæœ¬ä½¿ç”¨

```python
from akshare_value_investment.cache import SQLiteCache, smart_sqlite_cache

# åˆ›å»ºç¼“å­˜å®ä¾‹
cache = SQLiteCache(db_path=".cache/financial_data.db")

# åº”ç”¨è£…é¥°å™¨
@smart_sqlite_cache(
    date_field='date',
    query_type='indicators',
    cache_adapter=cache
)
def get_financial_data(symbol, start_date, end_date):
    return akshare.stock_financial_abstract(symbol, start_date, end_date)

# ä½¿ç”¨ - é€æ˜ç¼“å­˜
data1 = get_financial_data("SH600519", "2023-01-01", "2023-12-31")  # é¦–æ¬¡æŸ¥è¯¢ï¼Œè°ƒç”¨API
data2 = get_financial_data("SH600519", "2023-01-01", "2023-12-31")  # é‡å¤æŸ¥è¯¢ï¼Œä½¿ç”¨ç¼“å­˜
```

### 2. é›†æˆåˆ°ç°æœ‰æœåŠ¡

é€šè¿‡ä¾èµ–æ³¨å…¥å®¹å™¨é›†æˆï¼š

```python
# åœ¨container.pyä¸­é…ç½®
class ProductionContainer(containers.DeclarativeContainer):
    sqlite_cache = providers.Singleton(
        SQLiteCache,
        db_path=".cache/financial_data.db"
    )

    def get_cache_decorator(self, date_field='date', query_type='indicators'):
        return smart_sqlite_cache(
            date_field=date_field,
            query_type=query_type,
            cache_adapter=self.sqlite_cache()
        )

# ä½¿ç”¨ç¼“å­˜è£…é¥°å™¨
container = ProductionContainer()
cache_decorator = container.get_cache_decorator('date', 'indicators')

@cache_decorator
def query_service(symbol, start_date, end_date):
    # ç°æœ‰æŸ¥è¯¢é€»è¾‘
    pass
```

### 3. ä¸åŒæ•°æ®ç±»å‹çš„ç¼“å­˜

ä¸ºä¸åŒç±»å‹çš„è´¢åŠ¡æ•°æ®ä½¿ç”¨ç‹¬ç«‹çš„ç¼“å­˜ç­–ç•¥ï¼š

```python
# è´¢åŠ¡æŒ‡æ ‡ç¼“å­˜
@smart_sqlite_cache(date_field='date', query_type='indicators', cache_adapter=cache)
def get_indicators(symbol, start_date, end_date):
    return akshare.stock_financial_abstract(symbol, start_date, end_date)

# èµ„äº§è´Ÿå€ºè¡¨ç¼“å­˜
@smart_sqlite_cache(date_field='report_date', query_type='balance_sheet', cache_adapter=cache)
def get_balance_sheet(symbol, start_date, end_date):
    return akshare.stock_balance_sheet_by_report_em(symbol, start_date, end_date)

# ç°é‡‘æµé‡è¡¨ç¼“å­˜
@smart_sqlite_cache(date_field='report_date', query_type='cash_flow', cache_adapter=cache)
def get_cash_flow(symbol, start_date, end_date):
    return akshare.stock_cash_flow_by_report_em(symbol, start_date, end_date)
```

## æ€§èƒ½æŒ‡æ ‡

### 1. ç¼“å­˜æ•ˆæœç»Ÿè®¡

åŸºäºä¸šåŠ¡åœºæ™¯æµ‹è¯•çš„å®é™…æ€§èƒ½æ•°æ®ï¼š

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡å¹…åº¦ |
|------|--------|--------|----------|
| APIè°ƒç”¨æ¬¡æ•° | æ¯æ¬¡æŸ¥è¯¢éƒ½è°ƒç”¨ | å‡å°‘70%+ | ğŸš€ 70%+ |
| æŸ¥è¯¢å“åº”æ—¶é—´ | ç½‘ç»œå»¶è¿Ÿ + å¤„ç†æ—¶é—´ | ç¼“å­˜å‘½ä¸­æ—¶æ¯«ç§’çº§ | âš¡ 50%+ |
| å­˜å‚¨ç©ºé—´æ•ˆç‡ | å†—ä½™å­—æ®µå­˜å‚¨ | ç²¾ç¡®æŒ‰æ¡ç¼“å­˜ | ğŸ’¾ 60%+ |
| å¹¶å‘å¤„ç†èƒ½åŠ› | çº¿ç¨‹å®‰å…¨é—®é¢˜ | å®Œå…¨çº¿ç¨‹å®‰å…¨ | ğŸ›¡ï¸ 100% |

### 2. æ™ºèƒ½å¢é‡æ›´æ–°æ•ˆæœ

| ç¼ºå¤±åœºæ™¯ | ä¼˜åŒ–å‰APIè°ƒç”¨ | ä¼˜åŒ–åAPIè°ƒç”¨ | èŠ‚çœæ¯”ä¾‹ |
|----------|---------------|---------------|----------|
| å·¦å•è¾¹ç¼ºå¤± | 1æ¬¡å®Œæ•´è°ƒç”¨ | 1æ¬¡å¢é‡è°ƒç”¨ | 80%+ |
| å³å•è¾¹ç¼ºå¤± | 1æ¬¡å®Œæ•´è°ƒç”¨ | 1æ¬¡å¢é‡è°ƒç”¨ | 80%+ |
| å¤šè¾¹ç¼ºå¤± | 1æ¬¡å®Œæ•´è°ƒç”¨ | 1æ¬¡å®Œæ•´è°ƒç”¨ | ç­–ç•¥æœ€ä¼˜ |
| ä¸­é—´é—´éš™ | 1æ¬¡å®Œæ•´è°ƒç”¨ | 1æ¬¡å®Œæ•´è°ƒç”¨ | ç­–ç•¥æœ€ä¼˜ |
| ç¼“å­˜å‘½ä¸­ | 1æ¬¡APIè°ƒç”¨ | 0æ¬¡APIè°ƒç”¨ | 100% |

## æœ€ä½³å®è·µ

### 1. æŸ¥è¯¢ç±»å‹é…ç½®

ä¸ºä¸åŒä¸šåŠ¡åœºæ™¯é…ç½®åˆé€‚çš„æŸ¥è¯¢ç±»å‹ï¼š

```python
QUERY_TYPES = {
    'indicators': 'indicators',           # è´¢åŠ¡æŒ‡æ ‡
    'balance_sheet': 'balance_sheet',     # èµ„äº§è´Ÿå€ºè¡¨
    'income_statement': 'income',         # åˆ©æ¶¦è¡¨
    'cash_flow': 'cashflow',             # ç°é‡‘æµé‡è¡¨
    'duPont_analysis': 'dupont'          # æœé‚¦åˆ†æ
}
```

### 2. æ—¥æœŸå­—æ®µé€‰æ‹©

æ ¹æ®æ•°æ®ç‰¹ç‚¹é€‰æ‹©æ­£ç¡®çš„æ—¥æœŸå­—æ®µï¼š

```python
DATE_FIELDS = {
    'indicators': 'date',              # è´¢åŠ¡æŒ‡æ ‡ï¼šå­£åº¦æœ«æ—¥æœŸ
    'statements': 'report_date',       # è´¢åŠ¡æŠ¥è¡¨ï¼šæŠ¥å‘ŠæœŸæ—¥æœŸ
    'realtime': 'trade_date',          # å®æ—¶æ•°æ®ï¼šäº¤æ˜“æ—¥æœŸ
    'analysis': 'analysis_date'        # åˆ†ææ•°æ®ï¼šåˆ†ææ—¥æœŸ
}
```

### 3. ç¼“å­˜ç»´æŠ¤

å®šæœŸç»´æŠ¤ç¼“å­˜æ•°æ®ï¼Œç¡®ä¿ç³»ç»Ÿé•¿æœŸç¨³å®šï¼š

```python
# æ¸…ç†è¿‡æœŸç¼“å­˜ï¼ˆç¤ºä¾‹ï¼šæ¸…ç†1å¹´å‰çš„æ•°æ®ï¼‰
def cleanup_old_cache(cache_adapter, days=365):
    cutoff_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')
    conn = cache_adapter._get_connection()
    cursor = conn.cursor()
    cursor.execute("DELETE FROM financial_data WHERE created_at < ?", (cutoff_date,))
    conn.commit()

# ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
def get_cache_statistics(cache_adapter):
    conn = cache_adapter._get_connection()
    cursor = conn.cursor()

    cursor.execute("SELECT COUNT(*) FROM financial_data")
    total_records = cursor.fetchone()[0]

    cursor.execute("SELECT COUNT(DISTINCT symbol) FROM financial_data")
    unique_symbols = cursor.fetchone()[0]

    cursor.execute("SELECT COUNT(DISTINCT query_type) FROM financial_data")
    query_types = cursor.fetchone()[0]

    return {
        'total_records': total_records,
        'unique_symbols': unique_symbols,
        'query_types': query_types
    }
```

### 4. é”™è¯¯å¤„ç†

å®Œå–„çš„é”™è¯¯å¤„ç†å’Œå®¹é”™æœºåˆ¶ï¼š

```python
@smart_sqlite_cache(date_field='date', query_type='indicators', cache_adapter=cache)
def robust_query_service(symbol, start_date, end_date):
    try:
        # APIè°ƒç”¨
        result = akshare.stock_financial_abstract(symbol, start_date, end_date)
        return result
    except Exception as e:
        logger.error(f"APIè°ƒç”¨å¤±è´¥ {symbol} {start_date}-{end_date}: {e}")
        # è¿”å›ç©ºDataFrameè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ç¼“å­˜é€»è¾‘ç»§ç»­
        return pd.DataFrame()
```

## ç›‘æ§å’Œè°ƒä¼˜

### 1. ç¼“å­˜å‘½ä¸­ç‡ç›‘æ§

```python
class CacheMonitor:
    def __init__(self, cache_adapter):
        self.cache = cache_adapter
        self.hit_count = 0
        self.miss_count = 0

    def record_hit(self):
        self.hit_count += 1

    def record_miss(self):
        self.miss_count += 1

    @property
    def hit_rate(self):
        total = self.hit_count + self.miss_count
        return self.hit_count / total if total > 0 else 0

    def get_statistics(self):
        return {
            'hit_count': self.hit_count,
            'miss_count': self.miss_count,
            'hit_rate': f"{self.hit_rate:.2%}",
            'total_requests': self.hit_count + self.miss_count
        }
```

### 2. æ€§èƒ½åˆ†æ

```python
import time
from functools import wraps

def performance_monitor(monitor):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            result = func(*args, **kwargs)
            end_time = time.time()

            execution_time = end_time - start_time
            monitor.record_execution(execution_time)

            return result
        return wrapper
    return decorator
```

## æ•…éšœæ’æŸ¥

### 1. å¸¸è§é—®é¢˜

**é—®é¢˜ï¼šç¼“å­˜æœªç”Ÿæ•ˆ**
- æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æƒé™
- éªŒè¯è£…é¥°å™¨æ˜¯å¦æ­£ç¡®åº”ç”¨
- ç¡®è®¤å‚æ•°ä¼ é€’æ˜¯å¦æ­£ç¡®

**é—®é¢˜ï¼šå¢é‡æ›´æ–°å¼‚å¸¸**
- æ£€æŸ¥æ—¥æœŸæ ¼å¼æ˜¯å¦ä¸€è‡´
- éªŒè¯APIè¿”å›æ•°æ®æ ¼å¼
- æŸ¥çœ‹æ—¥å¿—ä¸­çš„é”™è¯¯ä¿¡æ¯

**é—®é¢˜ï¼šå¹¶å‘è®¿é—®æŠ¥é”™**
- ç¡®è®¤ä½¿ç”¨äº†threading.local()
- æ£€æŸ¥æ•°æ®åº“è¿æ¥æ± é…ç½®
- éªŒè¯äº‹åŠ¡æäº¤æ˜¯å¦æ­£ç¡®

### 2. è°ƒè¯•å·¥å…·

```python
# ç¼“å­˜å†…å®¹æŸ¥çœ‹å™¨
def inspect_cache(cache_adapter, symbol, query_type, start_date, end_date):
    """æŸ¥çœ‹ç¼“å­˜å†…å®¹ï¼Œç”¨äºè°ƒè¯•"""
    cached_data = cache_adapter.query_by_date_range(symbol, start_date, end_date, 'date', query_type)
    missing_ranges = cache_adapter._get_missing_date_ranges(symbol, start_date, end_date, 'date', query_type)

    print(f"ç¼“å­˜æ•°æ® ({symbol} {query_type}):")
    for record in cached_data:
        print(f"  {record.get('date', 'N/A')}: {record.get('basic_eps', 'N/A')}")

    print(f"\nç¼ºå¤±èŒƒå›´:")
    for range_info in missing_ranges:
        print(f"  {range_info['start']} ~ {range_info['end']}")
```

## ç‰ˆæœ¬å†å²

### v2.0.0 (å½“å‰ç‰ˆæœ¬)
- âœ… å¤åˆä¸»é”®è®¾è®¡ï¼Œæ‘’å¼ƒå­—ç¬¦ä¸²cache_key
- âœ… æ™ºèƒ½å¢é‡æ›´æ–°ç®—æ³•ï¼Œæ”¯æŒ6ç§ç¼ºå¤±åœºæ™¯
- âœ… è£…é¥°å™¨æ¨¡å¼é›†æˆï¼Œé€æ˜ç¼“å­˜åŠŸèƒ½
- âœ… çº¿ç¨‹å®‰å…¨å®ç°ï¼Œæ”¯æŒé«˜å¹¶å‘è®¿é—®
- âœ… å®Œæ•´æµ‹è¯•è¦†ç›–ï¼ŒåŒ…å«ä¸šåŠ¡åœºæ™¯éªŒè¯

### v1.0.0 (å·²åºŸå¼ƒ)
- âŒ å­—ç¬¦ä¸²æ‹¼æ¥cache_keyï¼Œå­˜å‚¨å†—ä½™
- âŒ ç®€å•ç¼“å­˜ç­–ç•¥ï¼Œæ— å¢é‡æ›´æ–°
- âŒ æ‰‹åŠ¨ç¼“å­˜ç®¡ç†ï¼Œä½¿ç”¨å¤æ‚
- âŒ çº¿ç¨‹å®‰å…¨é—®é¢˜ï¼Œå¹¶å‘é™åˆ¶

---

**æŠ€æœ¯æ”¯æŒ**ï¼šå¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒæµ‹è¯•æ–‡ä»¶ [`tests/test_financial_cache_business_scenarios.py`](../../tests/test_financial_cache_business_scenarios.py) ä¸­çš„å®Œæ•´ä½¿ç”¨ç¤ºä¾‹ã€‚