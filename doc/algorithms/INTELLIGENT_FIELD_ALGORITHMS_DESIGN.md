# æ™ºèƒ½å­—æ®µé€‰æ‹©ç®—æ³•è¯¦ç»†è®¾è®¡

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è®¾è®¡äº†æ™ºèƒ½å­—æ®µé€‰æ‹©å’Œæ¨èç³»ç»Ÿçš„ä¸‰å¤§æ ¸å¿ƒç®—æ³•ï¼šæ™ºèƒ½å­—æ®µè·¯ç”±ã€è·¨å¸‚åœºå¯¹æ¯”åˆ†æå’Œæ™ºèƒ½æ¨èå¼•æ“ã€‚è¿™äº›ç®—æ³•å…±åŒæ„æˆäº†ä»ç®€å•æŸ¥è¯¢åˆ°æ™ºèƒ½åˆ†æçš„å®Œæ•´æŠ€æœ¯æ ˆã€‚

**è®¾è®¡ç›®æ ‡**ï¼šå®ç°åŸºäºæŸ¥è¯¢ä¸Šä¸‹æ–‡ã€è´¢åŠ¡é€»è¾‘å’Œè·¨å¸‚åœºå¯¹æ¯”çš„æ™ºèƒ½å­—æ®µå¤„ç†ç³»ç»Ÿ

---

## ğŸ§  ç®—æ³•1ï¼šæ™ºèƒ½å­—æ®µè·¯ç”±ç®—æ³•

### 1.1 ç®—æ³•ç›®æ ‡

**æ ¸å¿ƒé—®é¢˜**ï¼šåŒä¸€æŸ¥è¯¢å¯èƒ½å¯¹åº”å¤šä¸ªä¸åŒæ•°æ®æºçš„å­—æ®µ
```
æŸ¥è¯¢ï¼š"å‡€åˆ©æ¶¦"
å€™é€‰å­—æ®µï¼š
- a_stock.financial_indicators.NET_PROFIT (è´¢åŠ¡æŒ‡æ ‡-å‡€åˆ©æ¶¦ç‡)
- a_stock.financial_statements.NET_PROFIT (è´¢åŠ¡ä¸‰è¡¨-å‡€åˆ©æ¶¦)
- hk_stock.financial_statements.NET_PROFIT (æ¸¯è‚¡è´¢åŠ¡ä¸‰è¡¨-å‡€åˆ©æ¶¦)
```

**è§£å†³æ–¹æ¡ˆ**ï¼šåŸºäºæŸ¥è¯¢æ„å›¾ã€å­—æ®µç‰¹å¾å’Œå¸‚åœºä¸Šä¸‹æ–‡çš„æ™ºèƒ½è·¯ç”±ç®—æ³•

### 1.2 ç®—æ³•æ¶æ„

```python
class IntelligentFieldRouter:
    """æ™ºèƒ½å­—æ®µè·¯ç”±å™¨"""

    def __init__(self, config_loader: NamespacedConfigLoader):
        self.config_loader = config_loader
        self.intent_analyzer = QueryIntentAnalyzer()
        self.candidate_ranker = CandidateRanker()
        self.context_analyzer = QueryContextAnalyzer()

    def route_field_query(self, query: str, symbol: str,
                         market_id: str) -> Optional[FieldRouteResult]:
        """æ™ºèƒ½è·¯ç”±å­—æ®µæŸ¥è¯¢"""

        # Step 1: æŸ¥è¯¢æ„å›¾åˆ†æ
        intent = self.intent_analyzer.analyze_intent(query)

        # Step 2: è·å–å€™é€‰å­—æ®µ
        candidates = self._get_candidates(query, market_id, intent)

        if not candidates:
            return None

        # Step 3: ä¸Šä¸‹æ–‡åˆ†æ
        context = self.context_analyzer.analyze_context(symbol, query)

        # Step 4: å€™é€‰å­—æ®µæ™ºèƒ½æ’åº
        ranked_candidates = self.candidate_ranker.rank_candidates(
            candidates, intent, context
        )

        # Step 5: è¿”å›æœ€ä½³åŒ¹é…
        return ranked_candidates[0]
```

### 1.3 æŸ¥è¯¢æ„å›¾åˆ†æç®—æ³•

```python
class QueryIntentAnalyzer:
    """æŸ¥è¯¢æ„å›¾åˆ†æå™¨"""

    def __init__(self):
        # è´¢åŠ¡æŒ‡æ ‡è¯†åˆ«æ¨¡å¼
        self.indicators_patterns = [
            r'.*ç‡$',           # ROE, ROA, æ¯›åˆ©ç‡
            r'.*æ¯”$',           # å¸‚ç›ˆç‡, å¸‚å‡€ç‡
            r'.*åº¦$',           # å‘¨è½¬åº¦, æ æ†åº¦
            r'.*ç³»æ•°$',         # è´å¡”ç³»æ•°
            r'æ¯è‚¡.*æ”¶ç›Š$',     # æ¯è‚¡æ”¶ç›Š
        ]

        # è´¢åŠ¡ä¸‰è¡¨è¯†åˆ«æ¨¡å¼
        self.statements_patterns = [
            r'.*æ€»é¢$',         # æ€»èµ„äº§, æ€»è´Ÿå€º, æ€»æ”¶å…¥
            r'.*åˆ©æ¶¦$',         # å‡€åˆ©æ¶¦, æ¯›åˆ©æ¶¦, è¥ä¸šåˆ©æ¶¦
            r'.*æˆæœ¬$',         # è¥ä¸šæˆæœ¬, é”€å”®æˆæœ¬
            r'.*æ”¶å…¥$',         # è¥ä¸šæ”¶å…¥, å…¶ä»–æ”¶å…¥
            r'.*èµ„äº§$',         # æµåŠ¨èµ„äº§, å›ºå®šèµ„äº§
        ]

    def analyze_intent(self, query: str) -> QueryIntent:
        """åˆ†ææŸ¥è¯¢æ„å›¾"""
        query_lower = query.lower()

        # è®¡ç®—å„ç±»åˆ«çš„åŒ¹é…å¾—åˆ†
        indicators_score = sum(
            len(re.findall(pattern, query_lower))
            for pattern in self.indicators_patterns
        )

        statements_score = sum(
            len(re.findall(pattern, query_lower))
            for pattern in self.statements_patterns
        )

        # åŸºäºå¾—åˆ†ç¡®å®šæ„å›¾
        if indicators_score > statements_score:
            return QueryIntent.FINANCIAL_INDICATORS
        elif statements_score > indicators_score:
            return QueryIntent.FINANCIAL_STATEMENTS
        else:
            return QueryIntent.AMBIGUOUS
```

### 1.4 å€™é€‰å­—æ®µæ’åºç®—æ³•

```python
class CandidateRanker:
    """å€™é€‰å­—æ®µæ’åºå™¨"""

    def rank_candidates(self, candidates: List[FieldCandidate],
                       intent: QueryIntent, context: QueryContext) -> List[FieldCandidate]:
        """æ™ºèƒ½æ’åºå€™é€‰å­—æ®µ"""

        scored_candidates = []

        for candidate in candidates:
            # è®¡ç®—ç»¼åˆå¾—åˆ†
            score = self._calculate_composite_score(candidate, intent, context)
            scored_candidates.append((score, candidate))

        # æŒ‰å¾—åˆ†é™åºæ’åº
        scored_candidates.sort(key=lambda x: x[0], reverse=True)
        return [candidate for _, candidate in scored_candidates]

    def _calculate_composite_score(self, candidate: FieldCandidate,
                                 intent: QueryIntent, context: QueryContext) -> float:
        """è®¡ç®—ç»¼åˆå¾—åˆ†"""
        score = 0.0

        # 1. æ„å›¾åŒ¹é…å¾—åˆ† (æƒé‡: 40%)
        intent_score = self._calculate_intent_score(candidate, intent)
        score += intent_score * 0.4

        # 2. ç›¸ä¼¼åº¦å¾—åˆ† (æƒé‡: 30%)
        similarity_score = candidate.similarity
        score += similarity_score * 0.3

        # 3. ä¼˜å…ˆçº§å¾—åˆ† (æƒé‡: 20%)
        priority_score = candidate.priority / 3.0  # å½’ä¸€åŒ–åˆ°0-1
        score += priority_score * 0.2

        # 4. ä¸Šä¸‹æ–‡åŒ¹é…å¾—åˆ† (æƒé‡: 10%)
        context_score = self._calculate_context_score(candidate, context)
        score += context_score * 0.1

        return score

    def _calculate_intent_score(self, candidate: FieldCandidate, intent: QueryIntent) -> float:
        """è®¡ç®—æ„å›¾åŒ¹é…å¾—åˆ†"""
        if intent == QueryIntent.AMBIGUOUS:
            # æ¨¡ç³ŠæŸ¥è¯¢æ—¶ï¼Œè´¢åŠ¡æŒ‡æ ‡ç¨å¾®ä¼˜å…ˆï¼ˆæ›´å¸¸ç”¨ï¼‰
            if candidate.source_type == DataSourceType.FINANCIAL_INDICATORS:
                return 0.9
            else:
                return 0.8
        elif candidate.source_type.value == intent.value:
            return 1.0  # å®Œå…¨åŒ¹é…
        else:
            return 0.3  # ä¸åŒ¹é…
```

---

## ğŸŒ ç®—æ³•2ï¼šè·¨å¸‚åœºå¯¹æ¯”åˆ†æç®—æ³•

### 2.1 ç®—æ³•ç›®æ ‡

**æ ¸å¿ƒåŠŸèƒ½**ï¼šå®ç°ä¸åŒå¸‚åœºé—´ç›¸åŒå­—æ®µçš„å¯¹æ¯”åˆ†æ
```
å¯¹æ¯”åœºæ™¯ï¼š
- è…¾è®¯(00700.HK) vs Meta(META) å‡€åˆ©æ¶¦å¯¹æ¯”
- å°ç±³(1810.HK) vs Apple(AAPL) è¥æ”¶å¯¹æ¯”
- è´µå·èŒ…å°(600519.SH) vs å¯å£å¯ä¹(KO) ROEå¯¹æ¯”
```

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š
- ä¼šè®¡å‡†åˆ™å·®å¼‚ï¼ˆIFRS vs US GAAP vs ä¸­å›½ä¼šè®¡å‡†åˆ™ï¼‰
- è´§å¸å•ä½è½¬æ¢
- è´¢åŠ¡æœŸé—´å¯¹é½
- å­—æ®µè¯­ä¹‰ä¸€è‡´æ€§

### 2.2 ç®—æ³•æ¶æ„

```python
class CrossMarketComparator:
    """è·¨å¸‚åœºå¯¹æ¯”åˆ†æå™¨"""

    def __init__(self, config_loader: NamespacedConfigLoader):
        self.config_loader = config_loader
        self.comparability_analyzer = FieldComparabilityAnalyzer()
        self.currency_converter = CurrencyConverter()
        self.accounting_standards_map = AccountingStandardsMap()

    def compare_fields(self, field_id: str,
                      markets: List[str] = None,
                      symbols: Dict[str, str] = None) -> CrossMarketComparison:
        """è·¨å¸‚åœºå­—æ®µå¯¹æ¯”åˆ†æ"""

        if markets is None:
            markets = ['a_stock', 'hk_stock', 'us_stock']

        # Step 1: è·å–å„å¸‚åœºå­—æ®µä¿¡æ¯
        market_fields = self._get_market_fields(field_id, markets)

        # Step 2: åˆ†æå­—æ®µå¯æ¯”æ€§
        comparability = self.comparability_analyzer.analyze(
            market_fields, field_id
        )

        if not comparability.is_comparable:
            return CrossMarketComparison(
                field_id=field_id,
                is_comparable=False,
                reason=comparability.reason
            )

        # Step 3: æ‰§è¡Œå¯¹æ¯”åˆ†æ
        comparison_result = self._perform_comparison(
            market_fields, symbols, comparability
        )

        return comparison_result
```

### 2.3 å­—æ®µå¯æ¯”æ€§åˆ†æç®—æ³•

```python
class FieldComparabilityAnalyzer:
    """å­—æ®µå¯æ¯”æ€§åˆ†æå™¨"""

    def analyze(self, market_fields: Dict[str, FieldInfo],
               field_id: str) -> ComparabilityResult:
        """åˆ†æå­—æ®µåœ¨ä¸åŒå¸‚åœºé—´çš„å¯æ¯”æ€§"""

        # 1. åŸºæœ¬å­˜åœ¨æ€§æ£€æŸ¥
        if len(market_fields) < 2:
            return ComparabilityResult(
                is_comparable=False,
                reason="éœ€è¦è‡³å°‘2ä¸ªå¸‚åœºçš„æ•°æ®æ‰èƒ½è¿›è¡Œå¯¹æ¯”"
            )

        # 2. è¯­ä¹‰ä¸€è‡´æ€§åˆ†æ
        semantic_score = self._analyze_semantic_consistency(market_fields)
        if semantic_score < 0.6:
            return ComparabilityResult(
                is_comparable=False,
                reason=f"å­—æ®µè¯­ä¹‰å·®å¼‚è¾ƒå¤§ï¼Œä¸€è‡´æ€§è¯„åˆ†: {semantic_score:.2f}"
            )

        # 3. ä¼šè®¡å‡†åˆ™å…¼å®¹æ€§åˆ†æ
        accounting_score = self._analyze_accounting_compatibility(
            market_fields, field_id
        )

        # 4. è®¡ç®—ç»¼åˆå¯æ¯”æ€§è¯„åˆ†
        overall_score = (semantic_score + accounting_score) / 2

        return ComparabilityResult(
            is_comparable=overall_score >= 0.7,
            comparability_score=overall_score,
            semantic_score=semantic_score,
            accounting_score=accounting_score,
            currency_conversion_needed=self._needs_currency_conversion(market_fields)
        )

    def _analyze_semantic_consistency(self, market_fields: Dict[str, FieldInfo]) -> float:
        """åˆ†æè¯­ä¹‰ä¸€è‡´æ€§"""
        names = [field.name for field in market_fields.values()]
        keywords_lists = [field.keywords for field in market_fields.values()]

        # ä½¿ç”¨æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—è¯­ä¹‰ä¸€è‡´æ€§
        name_similarity = self._calculate_text_similarity(names)
        keyword_similarity = self._calculate_keywords_similarity(keywords_lists)

        return (name_similarity + keyword_similarity) / 2

    def _calculate_text_similarity(self, texts: List[str]) -> float:
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦"""
        if len(texts) < 2:
            return 1.0

        # ä½¿ç”¨ç¼–è¾‘è·ç¦»è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦
        similarities = []
        for i in range(len(texts)):
            for j in range(i + 1, len(texts)):
                sim = 1 - (edit_distance(texts[i], texts[j]) /
                          max(len(texts[i]), len(texts[j])))
                similarities.append(sim)

        return sum(similarities) / len(similarities)
```

### 2.4 æ™ºèƒ½å¯¹æ¯”æ‰§è¡Œç®—æ³•

```python
class ComparisonExecutor:
    """å¯¹æ¯”æ‰§è¡Œå™¨"""

    def execute_comparison(self, market_fields: Dict[str, FieldInfo],
                          symbols: Dict[str, str],
                          comparability: ComparabilityResult) -> ComparisonResult:
        """æ‰§è¡Œå®é™…çš„å¯¹æ¯”åˆ†æ"""

        # Step 1: è·å–å®é™…æ•°æ®
        market_data = self._fetch_market_data(market_fields, symbols)

        # Step 2: æ•°æ®æ ‡å‡†åŒ–å¤„ç†
        normalized_data = self._normalize_data(
            market_data, comparability
        )

        # Step 3: è®¡ç®—å¯¹æ¯”æŒ‡æ ‡
        comparison_metrics = self._calculate_metrics(normalized_data)

        # Step 4: ç”Ÿæˆå¯¹æ¯”æ´å¯Ÿ
        insights = self._generate_insights(comparison_metrics)

        return ComparisonResult(
            field_id=market_fields[next(iter(market_fields))].field_id,
            market_data=market_data,
            normalized_data=normalized_data,
            comparison_metrics=comparison_metrics,
            insights=insights,
            comparability_info=comparability
        )

    def _normalize_data(self, market_data: Dict[str, Any],
                       comparability: ComparabilityResult) -> Dict[str, Any]:
        """æ•°æ®æ ‡å‡†åŒ–å¤„ç†"""
        normalized = {}

        for market_id, data in market_data.items():
            normalized_value = data['value']

            # è´§å¸è½¬æ¢
            if comparability.currency_conversion_needed:
                target_currency = 'USD'  # é»˜è®¤è½¬æ¢ä¸ºç¾å…ƒ
                source_currency = data['currency']
                normalized_value = self.currency_converter.convert(
                    normalized_value, source_currency, target_currency
                )

            # å•ä½ç»Ÿä¸€
            normalized_value = self._unify_units(normalized_value)

            normalized[market_id] = {
                'value': normalized_value,
                'currency': 'USD',
                'period': data['period'],
                'original_value': data['value']
            }

        return normalized
```

---

## ğŸ¯ ç®—æ³•3ï¼šæ™ºèƒ½æ¨èå¼•æ“ç®—æ³•

### 3.1 ç®—æ³•ç›®æ ‡

**æ ¸å¿ƒåŠŸèƒ½**ï¼šåŸºäºè´¢åŠ¡é€»è¾‘å’Œç”¨æˆ·è¡Œä¸ºçš„æ™ºèƒ½å­—æ®µæ¨è
```
æ¨èåœºæ™¯ï¼š
- æŸ¥è¯¢"å‡€åˆ©æ¶¦" â†’ æ¨èï¼šROEã€æ¯›åˆ©ç‡ã€è¥ä¸šæ”¶å…¥ã€å‡€åˆ©ç‡
- æŸ¥è¯¢"ROE" â†’ æ¨èï¼šROAã€å‡€åˆ©æ¶¦ã€å‡€èµ„äº§ã€èµ„äº§è´Ÿå€ºç‡
- æŸ¥è¯¢"æ€»èµ„äº§" â†’ æ¨èï¼šå‡€èµ„äº§ã€æ€»è´Ÿå€ºã€èµ„äº§è´Ÿå€ºç‡ã€èµ„äº§å‘¨è½¬ç‡
```

**æ¨èç­–ç•¥**ï¼š
1. **è´¢åŠ¡é€»è¾‘å…³è”**ï¼šåŸºäºè´¢åŠ¡åˆ†ææ¡†æ¶çš„å…³è”æ¨è
2. **å†å²æŸ¥è¯¢æ¨¡å¼**ï¼šåŸºäºç”¨æˆ·æŸ¥è¯¢å†å²çš„æ¨¡å¼æ¨è
3. **è¡Œä¸šç‰¹å¾**ï¼šåŸºäºè¡Œä¸šç‰¹ç‚¹çš„ä¸“ä¸šæ¨è
4. **å…±ç°åˆ†æ**ï¼šåŸºäºå­—æ®µåŒæ—¶å‡ºç°çš„ç»Ÿè®¡æ¨è

### 3.2 ç®—æ³•æ¶æ„

```python
class FieldRecommendationEngine:
    """æ™ºèƒ½å­—æ®µæ¨èå¼•æ“"""

    def __init__(self, config_loader: NamespacedConfigLoader):
        self.config_loader = config_loader
        self.logic_recommender = LogicBasedRecommender()
        self.pattern_recommender = PatternBasedRecommender()
        self.industry_recommender = IndustryBasedRecommender()
        self.cooccurrence_recommender = CooccurrenceBasedRecommender()
        self.recommendation_merger = RecommendationMerger()

    def recommend_fields(self, primary_field: str, market_id: str,
                        symbol: str = None, limit: int = 5) -> List[FieldRecommendation]:
        """ç”Ÿæˆå­—æ®µæ¨è"""

        # Step 1: è·å–å„ç±»æ¨è
        logic_recommendations = self.logic_recommender.recommend(
            primary_field, market_id, symbol
        )

        pattern_recommendations = self.pattern_recommender.recommend(
            primary_field, market_id, symbol
        )

        industry_recommendations = self.industry_recommender.recommend(
            primary_field, market_id, symbol
        )

        cooccurrence_recommendations = self.cooccurrence_recommender.recommend(
            primary_field, market_id
        )

        # Step 2: åˆå¹¶å’Œæ’åºæ¨è
        all_recommendations = [
            logic_recommendations,
            pattern_recommendations,
            industry_recommendations,
            cooccurrence_recommendations
        ]

        merged_recommendations = self.recommendation_merger.merge_and_rank(
            all_recommendations, primary_field, market_id
        )

        return merged_recommendations[:limit]
```

### 3.3 è´¢åŠ¡é€»è¾‘æ¨èç®—æ³•

```python
class LogicBasedRecommender:
    """åŸºäºè´¢åŠ¡é€»è¾‘çš„æ¨èå™¨"""

    def __init__(self):
        # è´¢åŠ¡åˆ†æé€»è¾‘æ˜ å°„è¡¨
        self.financial_logic_map = {
            # ç›ˆåˆ©èƒ½åŠ›åˆ†æ
            'NET_PROFIT': [
                ('ROE', 'å‡€èµ„äº§æ”¶ç›Šç‡ï¼Œè¡¡é‡è‚¡ä¸œæƒç›Šå›æŠ¥ç‡'),
                ('ROA', 'æ€»èµ„äº§æ”¶ç›Šç‡ï¼Œè¡¡é‡èµ„äº§ä½¿ç”¨æ•ˆç‡'),
                ('NET_PROFIT_MARGIN', 'å‡€åˆ©ç‡ï¼Œè¡¡é‡ç›ˆåˆ©èƒ½åŠ›'),
                ('GROSS_PROFIT_MARGIN', 'æ¯›åˆ©ç‡ï¼Œè¡¡é‡äº§å“ç«äº‰åŠ›'),
                ('OPERATING_PROFIT_MARGIN', 'è¥ä¸šåˆ©æ¶¦ç‡ï¼Œè¡¡é‡ç»è¥æ•ˆç‡')
            ],

            # å¿å€ºèƒ½åŠ›åˆ†æ
            'TOTAL_ASSETS': [
                ('TOTAL_LIABILITIES', 'æ€»è´Ÿå€ºï¼Œä¸æ€»èµ„äº§å½¢æˆèµ„äº§è´Ÿå€ºè¡¨ç»“æ„'),
                ('NET_ASSETS', 'å‡€èµ„äº§ï¼Œè¡¡é‡å…¬å¸å‡€å€¼'),
                ('DEBT_TO_ASSET_RATIO', 'èµ„äº§è´Ÿå€ºç‡ï¼Œè¡¡é‡è´¢åŠ¡æ æ†'),
                ('CURRENT_ASSETS', 'æµåŠ¨èµ„äº§ï¼Œè¡¡é‡çŸ­æœŸå¿å€ºèƒ½åŠ›'),
                ('FIXED_ASSETS', 'å›ºå®šèµ„äº§ï¼Œè¡¡é‡é•¿æœŸèµ„äº§ç»“æ„')
            ],

            # è¿è¥æ•ˆç‡åˆ†æ
            'TOTAL_REVENUE': [
                ('NET_PROFIT', 'å‡€åˆ©æ¶¦ï¼Œè¡¡é‡æœ€ç»ˆç›ˆåˆ©'),
                ('OPERATING_PROFIT', 'è¥ä¸šåˆ©æ¶¦ï¼Œè¡¡é‡ä¸»è¥ä¸šåŠ¡ç›ˆåˆ©'),
                ('GROSS_PROFIT', 'æ¯›åˆ©æ¶¦ï¼Œè¡¡é‡äº§å“/æœåŠ¡ç›ˆåˆ©èƒ½åŠ›'),
                ('REVENUE_GROWTH_RATE', 'è¥æ”¶å¢é•¿ç‡ï¼Œè¡¡é‡æˆé•¿æ€§'),
                ('OPERATING_COSTS', 'è¥ä¸šæˆæœ¬ï¼Œåˆ†ææˆæœ¬ç»“æ„')
            ],

            # æŠ•èµ„å›æŠ¥åˆ†æ
            'ROE': [
                ('ROA', 'æ€»èµ„äº§æ”¶ç›Šç‡ï¼Œåˆ†ææ æ†æ•ˆåº”'),
                ('NET_PROFIT', 'å‡€åˆ©æ¶¦ï¼ŒROEçš„åˆ†å­'),
                ('NET_ASSETS', 'å‡€èµ„äº§ï¼ŒROEçš„åˆ†æ¯'),
                ('RETURN_ON invested_CAPital', 'æŠ•å…¥èµ„æœ¬å›æŠ¥ç‡'),
                ('DUPONT_ROE', 'æœé‚¦åˆ†æROEåˆ†è§£')
            ]
        }

    def recommend(self, primary_field: str, market_id: str,
                 symbol: str = None) -> List[FieldRecommendation]:
        """åŸºäºè´¢åŠ¡é€»è¾‘ç”Ÿæˆæ¨è"""

        recommendations = []

        # è·å–é€»è¾‘å…³è”å­—æ®µ
        logic_fields = self.financial_logic_map.get(primary_field, [])

        for field_id, reason in logic_fields:
            field_info = self._get_field_info(field_id, market_id)
            if field_info:
                # è®¡ç®—æ¨èç½®ä¿¡åº¦
                confidence = self._calculate_logic_confidence(
                    primary_field, field_id, market_id
                )

                recommendations.append(FieldRecommendation(
                    field_id=field_id,
                    field_info=field_info,
                    reason=reason,
                    confidence=confidence,
                    recommendation_type=RecommendationType.FINANCIAL_LOGIC
                ))

        return recommendations

    def _calculate_logic_confidence(self, primary_field: str,
                                  recommended_field: str, market_id: str) -> float:
        """è®¡ç®—è´¢åŠ¡é€»è¾‘æ¨èç½®ä¿¡åº¦"""

        # åŸºç¡€ç½®ä¿¡åº¦ï¼ˆåŸºäºå…³è”å¼ºåº¦ï¼‰
        base_confidence = 0.8

        # æ ¹æ®å­—æ®µé‡è¦æ€§è°ƒæ•´
        importance_weights = {
            'ROE': 0.9, 'ROA': 0.8, 'NET_PROFIT': 0.9,
            'TOTAL_REVENUE': 0.8, 'TOTAL_ASSETS': 0.7
        }

        field_weight = importance_weights.get(recommended_field, 0.6)

        return base_confidence * field_weight
```

### 3.4 å…±ç°åˆ†ææ¨èç®—æ³•

```python
class CooccurrenceBasedRecommender:
    """åŸºäºå…±ç°åˆ†æçš„æ¨èå™¨"""

    def __init__(self):
        # æ¨¡æ‹Ÿçš„æŸ¥è¯¢å…±ç°ç»Ÿè®¡æ•°æ®
        # åœ¨å®é™…ç³»ç»Ÿä¸­ï¼Œè¿™äº›æ•°æ®æ¥è‡ªç”¨æˆ·æŸ¥è¯¢å†å²
        self.cooccurrence_matrix = {
            'NET_PROFIT': {
                'ROE': 45, 'ROA': 38, 'NET_PROFIT_MARGIN': 52,
                'TOTAL_REVENUE': 67, 'OPERATING_PROFIT': 41
            },
            'ROE': {
                'ROA': 58, 'NET_PROFIT': 45, 'NET_ASSETS': 32,
                'DEBT_TO_ASSET_RATIO': 28, 'DUPONT_ROE': 15
            },
            'TOTAL_REVENUE': {
                'NET_PROFIT': 67, 'OPERATING_PROFIT': 43,
                'GROSS_PROFIT': 39, 'REVENUE_GROWTH_RATE': 35,
                'OPERATING_COSTS': 31
            }
        }

        self.total_queries = 10000  # æ€»æŸ¥è¯¢æ•°ï¼ˆç¤ºä¾‹ï¼‰

    def recommend(self, primary_field: str, market_id: str) -> List[FieldRecommendation]:
        """åŸºäºå…±ç°åˆ†æç”Ÿæˆæ¨è"""

        recommendations = []

        # è·å–å…±ç°æ•°æ®
        cooccurrence_data = self.cooccurrence_matrix.get(primary_field, {})

        for field_id, cooccurrence_count in cooccurrence_data.items():
            field_info = self._get_field_info(field_id, market_id)
            if field_info:
                # è®¡ç®—å…±ç°ç½®ä¿¡åº¦
                confidence = cooccurrence_count / self.total_queries

                # è®¡ç®—æå‡åº¦
                lift = self._calculate_lift(primary_field, field_id, cooccurrence_count)

                recommendations.append(FieldRecommendation(
                    field_id=field_id,
                    field_info=field_info,
                    reason=f"ä¸{primary_field}ç»å¸¸ä¸€èµ·æŸ¥è¯¢ï¼ˆ{cooccurrence_count}æ¬¡ï¼‰",
                    confidence=confidence,
                    recommendation_type=RecommendationType.COOCURRENCE,
                    metadata={'lift': lift, 'cooccurrence_count': cooccurrence_count}
                ))

        # æŒ‰ç½®ä¿¡åº¦æ’åº
        recommendations.sort(key=lambda x: x.confidence, reverse=True)

        return recommendations

    def _calculate_lift(self, primary_field: str, recommended_field: str,
                       cooccurrence_count: int) -> float:
        """è®¡ç®—æ¨èæå‡åº¦"""

        primary_count = self._get_field_query_count(primary_field)
        recommended_count = self._get_field_query_count(recommended_field)

        if primary_count == 0 or recommended_count == 0:
            return 1.0

        # Lift = P(A,B) / (P(A) * P(B))
        expected_cooccurrence = (primary_count * recommended_count) / self.total_queries

        if expected_cooccurrence == 0:
            return float('inf')

        return cooccurrence_count / expected_cooccurrence
```

---

## ğŸ“Š ç®—æ³•æ€§èƒ½è¯„ä¼°

### 4.1 æ—¶é—´å¤æ‚åº¦åˆ†æ

| ç®—æ³•ç»„ä»¶ | æ—¶é—´å¤æ‚åº¦ | è¯´æ˜ |
|----------|------------|------|
| æŸ¥è¯¢æ„å›¾åˆ†æ | O(1) | æ¨¡å¼åŒ¹é…ï¼Œå¸¸æ•°æ—¶é—´ |
| å€™é€‰å­—æ®µè·å– | O(m) | mä¸ºå¸‚åœºé…ç½®çš„å­—æ®µæ•° |
| å­—æ®µæ’åº | O(n log n) | nä¸ºå€™é€‰å­—æ®µæ•°é‡ |
| è·¨å¸‚åœºå¯¹æ¯” | O(kÂ²) | kä¸ºå¯¹æ¯”çš„å¸‚åœºæ•°é‡ |
| å…±ç°åˆ†æ | O(1) | åŸºäºé¢„è®¡ç®—çš„ç»Ÿè®¡çŸ©é˜µ |

### 4.2 ç©ºé—´å¤æ‚åº¦åˆ†æ

| æ•°æ®ç»“æ„ | ç©ºé—´å¤æ‚åº¦ | è¯´æ˜ |
|----------|------------|------|
| é…ç½®ç¼“å­˜ | O(total_fields) | æ‰€æœ‰å­—æ®µçš„é…ç½®ä¿¡æ¯ |
| å…±ç°çŸ©é˜µ | O(fieldsÂ²) | å­—æ®µé—´å…±ç°ç»Ÿè®¡ |
| æŸ¥è¯¢å†å² | O(query_history) | ç”¨æˆ·æŸ¥è¯¢å†å²è®°å½• |
| æ¨èç¼“å­˜ | O(recommendations) | æ¨èç»“æœç¼“å­˜ |

### 4.3 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

```python
class PerformanceOptimizer:
    """æ€§èƒ½ä¼˜åŒ–å™¨"""

    def __init__(self):
        self.field_index = FieldIndex()      # å­—æ®µç´¢å¼•
        self.recommendation_cache = LRUCache(maxsize=1000)  # æ¨èç¼“å­˜
        self.comparison_cache = LRUCache(maxsize=500)       # å¯¹æ¯”ç¼“å­˜

    def optimize_field_search(self, query: str, market_id: str) -> List[FieldCandidate]:
        """ä¼˜åŒ–çš„å­—æ®µæœç´¢"""

        # 1. ä½¿ç”¨ç´¢å¼•å¿«é€Ÿå®šä½
        indexed_candidates = self.field_index.search(query, market_id)

        # 2. ç¼“å­˜æŸ¥è¯¢ç»“æœ
        cache_key = f"{query}:{market_id}"
        if cache_key in self.recommendation_cache:
            return self.recommendation_cache[cache_key]

        # 3. ç»“æœç¼“å­˜
        self.recommendation_cache[cache_key] = indexed_candidates

        return indexed_candidates

    def preload_common_queries(self):
        """é¢„åŠ è½½å¸¸è§æŸ¥è¯¢"""
        common_queries = [
            "ROE", "å‡€åˆ©æ¶¦", "è¥ä¸šæ”¶å…¥", "æ€»èµ„äº§", "ROA",
            "æ¯›åˆ©ç‡", "èµ„äº§è´Ÿå€ºç‡", "æ¯è‚¡æ”¶ç›Š"
        ]

        for query in common_queries:
            for market_id in ['a_stock', 'hk_stock', 'us_stock']:
                self.optimize_field_search(query, market_id)
```

---

## ğŸ”„ ç®—æ³•é›†æˆä¸æµ‹è¯•

### 5.1 TDDæµ‹è¯•ç­–ç•¥

**æµ‹è¯•å±‚æ¬¡**ï¼š
1. **å•å…ƒæµ‹è¯•**ï¼šæ¯ä¸ªç®—æ³•ç»„ä»¶çš„ç‹¬ç«‹æµ‹è¯•
2. **é›†æˆæµ‹è¯•**ï¼šç®—æ³•é—´åä½œçš„æµ‹è¯•
3. **ç«¯åˆ°ç«¯æµ‹è¯•**ï¼šå®Œæ•´ç”¨æˆ·åœºæ™¯çš„æµ‹è¯•
4. **æ€§èƒ½æµ‹è¯•**ï¼šå“åº”æ—¶é—´å’Œååé‡æµ‹è¯•

**æµ‹è¯•ç”¨ä¾‹è®¾è®¡**ï¼š
```python
class IntelligentAlgorithmsTestSuite:
    """æ™ºèƒ½ç®—æ³•æµ‹è¯•å¥—ä»¶"""

    def test_field_routing_accuracy(self):
        """æµ‹è¯•å­—æ®µè·¯ç”±å‡†ç¡®æ€§"""
        test_cases = [
            ("ROE", "600519", "a_stock", DataSourceType.FINANCIAL_INDICATORS),
            ("å‡€åˆ©æ¶¦", "600519", "a_stock", DataSourceType.FINANCIAL_STATEMENTS),
            ("Total Revenue", "AAPL", "us_stock", DataSourceType.FINANCIAL_STATEMENTS),
        ]

        for query, symbol, market, expected_source in test_cases:
            result = self.router.route_field_query(query, symbol, market)
            assert result.source_type == expected_source

    def test_cross_market_comparison_validity(self):
        """æµ‹è¯•è·¨å¸‚åœºå¯¹æ¯”æœ‰æ•ˆæ€§"""
        comparison = self.comparator.compare_fields("NET_PROFIT")

        assert comparison.is_comparable == True
        assert len(comparison.market_data) >= 2
        assert comparison.comparison_metrics is not None

    def test_recommendation_relevance(self):
        """æµ‹è¯•æ¨èç›¸å…³æ€§"""
        recommendations = self.engine.recommend_fields("NET_PROFIT", "a_stock")

        # éªŒè¯æ¨èç»“æœçš„åˆç†æ€§
        recommended_fields = [rec.field_id for rec in recommendations]
        expected_related_fields = ['ROE', 'NET_PROFIT_MARGIN', 'TOTAL_REVENUE']

        overlap = set(recommended_fields) & set(expected_related_fields)
        assert len(overlap) >= len(expected_related_fields) // 2
```

### 5.2 A/Bæµ‹è¯•æ¡†æ¶

```python
class AlgorithmABTest:
    """ç®—æ³•A/Bæµ‹è¯•æ¡†æ¶"""

    def __init__(self):
        self.control_algorithm = BaselineFieldRouter()
        self.test_algorithm = IntelligentFieldRouter()
        self.metrics_collector = MetricsCollector()

    def run_ab_test(self, test_queries: List[str]) -> ABTestResult:
        """è¿è¡ŒA/Bæµ‹è¯•"""

        results = {
            'control': {'satisfaction': [], 'response_time': []},
            'test': {'satisfaction': [], 'response_time': []}
        }

        for query in test_queries:
            # æµ‹è¯•å¯¹ç…§ç»„
            start_time = time.time()
            control_result = self.control_algorithm.route_field_query(query)
            control_time = time.time() - start_time

            # æµ‹è¯•å®éªŒç»„
            start_time = time.time()
            test_result = self.test_algorithm.route_field_query(query)
            test_time = time.time() - start_time

            # æ”¶é›†ç»“æœ
            results['control']['response_time'].append(control_time)
            results['test']['response_time'].append(test_time)

            # æ¨¡æ‹Ÿç”¨æˆ·æ»¡æ„åº¦è¯„åˆ†
            control_satisfaction = self._simulate_user_satisfaction(control_result)
            test_satisfaction = self._simulate_user_satisfaction(test_result)

            results['control']['satisfaction'].append(control_satisfaction)
            results['test']['satisfaction'].append(test_satisfaction)

        return self._analyze_ab_test_results(results)
```

---

## ğŸ“ˆ é¢„æœŸæ•ˆæœä¸ä»·å€¼

### 6.1 ç”¨æˆ·ä½“éªŒæå‡

**æŸ¥è¯¢å‡†ç¡®ç‡**ï¼š
- ä¼ ç»Ÿæ–¹å¼ï¼šåŸºäºå­—ç¬¦ä¸²åŒ¹é…ï¼Œå‡†ç¡®ç‡çº¦60%
- æ™ºèƒ½è·¯ç”±ï¼šåŸºäºæ„å›¾åˆ†æï¼Œå‡†ç¡®ç‡é¢„æœŸ85%+

**æ¨èç›¸å…³æ€§**ï¼š
- æ— æ¨èï¼šç”¨æˆ·éœ€è¦æ‰‹åŠ¨æŸ¥æ‰¾ç›¸å…³å­—æ®µ
- æ™ºèƒ½æ¨èï¼šåŸºäºè´¢åŠ¡é€»è¾‘ï¼Œç›¸å…³æ€§é¢„æœŸ80%+

**åˆ†ææ·±åº¦**ï¼š
- å•ä¸€æŸ¥è¯¢ï¼šä»…è¿”å›ç›®æ ‡å­—æ®µ
- æ™ºèƒ½åˆ†æï¼šæä¾›å…³è”å­—æ®µã€å¯¹æ¯”åˆ†æã€è¶‹åŠ¿æ´å¯Ÿ

### 6.2 æŠ€æœ¯ä»·å€¼ä½“ç°

**ç®—æ³•åˆ›æ–°**ï¼š
- é¦–åˆ›è´¢åŠ¡é¢†åŸŸä¸“ç”¨çš„å­—æ®µè·¯ç”±ç®—æ³•
- ç»“åˆè´¢åŠ¡é€»è¾‘çš„æ™ºèƒ½æ¨èå¼•æ“
- æ”¯æŒå¤šå¸‚åœºå¯¹æ¯”çš„æ™ºèƒ½åˆ†ææ¡†æ¶

**ç³»ç»Ÿæ€§èƒ½**ï¼š
- æŸ¥è¯¢å“åº”æ—¶é—´ï¼šå¹³å‡ < 50ms
- æ¨èç”Ÿæˆæ—¶é—´ï¼šå¹³å‡ < 100ms
- è·¨å¸‚åœºå¯¹æ¯”ï¼šå¹³å‡ < 200ms

**å¯æ‰©å±•æ€§**ï¼š
- æ”¯æŒæ–°å¸‚åœºçš„æ— ç¼æ¥å…¥
- æ”¯æŒæ–°æ¨èç®—æ³•çš„æ’ä»¶åŒ–æ‰©å±•
- æ”¯æŒç”¨æˆ·ä¸ªæ€§åŒ–æ¨¡å‹çš„è®­ç»ƒ

---

## ğŸ‰ æ€»ç»“

æ™ºèƒ½å­—æ®µé€‰æ‹©å’Œæ¨èç³»ç»Ÿçš„ä¸‰å¤§æ ¸å¿ƒç®—æ³•å…±åŒæ„æˆäº†ä¸€ä¸ªå®Œæ•´çš„æ™ºèƒ½è´¢åŠ¡åˆ†ææŠ€æœ¯æ ˆï¼š

1. **æ™ºèƒ½å­—æ®µè·¯ç”±ç®—æ³•**ï¼šè§£å†³å­—æ®µæºæ­§ä¹‰ï¼Œå®ç°ç²¾å‡†æŸ¥è¯¢
2. **è·¨å¸‚åœºå¯¹æ¯”åˆ†æç®—æ³•**ï¼šçªç ´å¸‚åœºè¾¹ç•Œï¼Œå®ç°å…¨çƒå¯¹æ¯”
3. **æ™ºèƒ½æ¨èå¼•æ“ç®—æ³•**ï¼šåŸºäºè´¢åŠ¡é€»è¾‘ï¼Œæä¾›å…³è”åˆ†æ

è¿™äº›ç®—æ³•çš„å®ç°å°†æŠŠakshare-value-investmenté¡¹ç›®ä»ç®€å•çš„è´¢åŠ¡æ•°æ®æŸ¥è¯¢å·¥å…·å‡çº§ä¸ºæ™ºèƒ½è´¢åŠ¡åˆ†æå¹³å°ï¼Œä¸ºç”¨æˆ·æä¾›å‰æ‰€æœªæœ‰çš„æŠ•èµ„åˆ†æä½“éªŒã€‚

**æŠ€æœ¯æˆç†Ÿåº¦**ï¼šâœ… ç®—æ³•è®¾è®¡å®Œæˆï¼Œå‡†å¤‡å®ç°é˜¶æ®µ
**é¢„æœŸå®Œæˆæ—¶é—´**ï¼š2025-11-20
**åˆ›æ–°ç­‰çº§**ï¼šğŸš€ è´¢åŠ¡æŠ€æœ¯é¢†åŸŸçš„é‡å¤§çªç ´

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0
**æœ€åæ›´æ–°**ï¼š2025-11-13
**è®¾è®¡çŠ¶æ€**ï¼šâœ… è¯¦ç»†è®¾è®¡å®Œæˆ