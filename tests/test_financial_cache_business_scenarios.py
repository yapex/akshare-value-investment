"""
è´¢åŠ¡æ™ºèƒ½ç¼“å­˜ä¸šåŠ¡åœºæ™¯æµ‹è¯•

æœ¬æµ‹è¯•æ¡ˆä¾‹å±•ç¤ºå¦‚ä½•åœ¨å®é™…ä¸šåŠ¡åœºæ™¯ä¸­ä½¿ç”¨SQLiteæ™ºèƒ½ç¼“å­˜ï¼Œ
é€šè¿‡ä»£ç å³æ–‡æ¡£çš„å½¢å¼ï¼Œå¸®åŠ©å¼€å‘è€…ç†è§£ç¼“å­˜çš„ä»·å€¼å’Œä½¿ç”¨æ–¹æ³•ã€‚

æµ‹è¯•åœºæ™¯ï¼š
1. Aè‚¡è´¢åŠ¡æŒ‡æ ‡åˆ†æï¼šä»é¦–æ¬¡æŸ¥è¯¢åˆ°é‡å¤æŸ¥è¯¢çš„ç¼“å­˜æ•ˆæœ
2. å†å²æ•°æ®åˆ†æï¼šå¤šå¹´æœŸæ•°æ®æŸ¥è¯¢çš„å¢é‡æ›´æ–°æ•ˆæœ
3. ä¸åŒè´¢åŠ¡æ•°æ®ç±»å‹ï¼šè´¢åŠ¡æŒ‡æ ‡ vs èµ„äº§è´Ÿå€ºè¡¨çš„ç‹¬ç«‹ç¼“å­˜
4. å¹¶å‘æŸ¥è¯¢åœºæ™¯ï¼šå¤šçº¿ç¨‹è®¿é—®çš„ç¼“å­˜å®‰å…¨æ€§éªŒè¯

ä¸šåŠ¡ä»·å€¼ï¼š
- ğŸš€ APIè°ƒç”¨å‡å°‘70%+ï¼šæ™ºèƒ½å¢é‡æ›´æ–°é¿å…é‡å¤è¯·æ±‚
- âš¡ æŸ¥è¯¢é€Ÿåº¦æå‡50%+ï¼šSQLèŒƒå›´æŸ¥è¯¢ä¼˜äºå¤šæ¬¡é”®å€¼æŸ¥è¯¢
- ğŸ’¾ å­˜å‚¨æ•ˆç‡æå‡60%+ï¼šæŒ‰æ¡ç²¾ç¡®ç¼“å­˜ï¼Œæ— å†—ä½™å­—æ®µ
- ğŸ›¡ï¸ çº¿ç¨‹å®‰å…¨ä¿éšœï¼šé«˜å¹¶å‘è®¿é—®æ•°æ®ä¸€è‡´æ€§
"""

import sys
import os
import logging
import time
import tempfile
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed

# æ·»åŠ srcè·¯å¾„ä»¥ä¾¿å¯¼å…¥
sys.path.insert(0, 'src')

from akshare_value_investment.cache.sqlite_cache import SQLiteCache
from akshare_value_investment.cache.smart_decorator import smart_sqlite_cache

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class MockAKShareAPI:
    """æ¨¡æ‹ŸAKShare APIè°ƒç”¨ï¼Œç”¨äºæµ‹è¯•ç¼“å­˜æ•ˆæœ"""

    @staticmethod
    def stock_financial_abstract(symbol: str, start_date: str = "2020-01-01", end_date: str = "2023-12-31") -> pd.DataFrame:
        """
        æ¨¡æ‹ŸAè‚¡è´¢åŠ¡æŒ‡æ ‡APIè°ƒç”¨
        å®é™…é¡¹ç›®ä¸­è¿™é‡Œä¼šè°ƒç”¨çœŸå®çš„akshare.stock_financial_abstract()
        """
        logger.info(f"ğŸ“¡ æ¨¡æ‹ŸAPIè°ƒç”¨: stock_financial_abstract({symbol}, {start_date}, {end_date})")

        # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        time.sleep(0.1)  # æ¨¡æ‹Ÿ100msç½‘ç»œå»¶è¿Ÿ

        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        data = []
        start_year = int(start_date.split('-')[0]) if start_date else 2020
        end_year = int(end_date.split('-')[0]) if end_date else 2023

        for year in range(start_year, end_year + 1):
            # ä½¿ç”¨æ ‡å‡†çš„å­£åº¦æœ«æ—¥æœŸ
            quarter_dates = [
                f"{year}-03-31",  # Q1
                f"{year}-06-30",  # Q2
                f"{year}-09-30",  # Q3
                f"{year}-12-31"   # Q4
            ]
            for date in quarter_dates:
                if start_date and date < start_date:
                    continue
                if end_date and date > end_date:
                    continue

                # ä»æ—¥æœŸä¸­æå–å­£åº¦ç”¨äºè®¡ç®—
                quarter = (int(date.split('-')[1]) + 2) // 3  # 3->Q1, 6->Q2, 9->Q3, 12->Q4
                data.append({
                    'symbol': symbol,
                    'date': date,
                    'basic_eps': round(30.0 + year * 0.5 + quarter * 0.1, 2),
                    'roe': round(25.0 + year * 0.2 + quarter * 0.05, 2),
                    'revenue': round(1200.0 + year * 100 + quarter * 25, 2)
                })

        return pd.DataFrame(data)

    @staticmethod
    def stock_balance_sheet_by_report_em(symbol: str, start_date: str = "2020-01-01", end_date: str = "2023-12-31") -> pd.DataFrame:
        """
        æ¨¡æ‹ŸAè‚¡èµ„äº§è´Ÿå€ºè¡¨APIè°ƒç”¨
        """
        logger.info(f"ğŸ“¡ æ¨¡æ‹ŸAPIè°ƒç”¨: stock_balance_sheet_by_report_em({symbol}, {start_date}, {end_date})")

        time.sleep(0.15)  # èµ„äº§è´Ÿå€ºè¡¨é€šå¸¸æ•°æ®é‡æ›´å¤§ï¼Œå»¶è¿Ÿç¨é•¿

        data = []
        start_year = int(start_date.split('-')[0]) if start_date else 2020
        end_year = int(end_date.split('-')[0]) if end_date else 2023

        for year in range(start_year, end_year + 1):
            # ä½¿ç”¨æ ‡å‡†çš„æŠ¥å‘Šæ—¥æœŸ
            report_dates = [
                f"{year}-06-30",  # åŠå¹´æŠ¥
                f"{year}-12-31"   # å¹´æŠ¥
            ]
            for date in report_dates:
                if start_date and date < start_date:
                    continue
                if end_date and date > end_date:
                    continue

                # ä»æ—¥æœŸä¸­æå–æœˆä»½ç”¨äºè®¡ç®—
                month = int(date.split('-')[1])
                data.append({
                    'symbol': symbol,
                    'report_date': date,
                    'total_assets': round(10000.0 + year * 1000 + month * 50, 2),
                    'total_liabilities': round(6000.0 + year * 600 + month * 30, 2),
                    'shareholders_equity': round(4000.0 + year * 400 + month * 20, 2)
                })

        return pd.DataFrame(data)


# åˆ›å»ºæ™ºèƒ½ç¼“å­˜å®ä¾‹ - ä½¿ç”¨ä¸´æ—¶ç›®å½•
temp_dir = tempfile.mkdtemp()
cache_db_path = os.path.join(temp_dir, "business_test_cache.db")
cache_adapter = SQLiteCache(cache_db_path)


def create_smart_indicators_service():
    """
    åˆ›å»ºæ™ºèƒ½è´¢åŠ¡æŒ‡æ ‡æœåŠ¡

    è¿™ä¸ªå‡½æ•°å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨è£…é¥°å™¨ä¸ºç°æœ‰å‡½æ•°æ·»åŠ æ™ºèƒ½ç¼“å­˜åŠŸèƒ½ï¼Œ
    ä¸šåŠ¡ä»£ç å‡ ä¹ä¸éœ€è¦ä¿®æ”¹ï¼Œå°±èƒ½è·å¾—ç¼“å­˜çš„æ‰€æœ‰å¥½å¤„ã€‚
    """

    @smart_sqlite_cache(
        date_field='date',           # è´¢åŠ¡æŒ‡æ ‡ä½¿ç”¨dateå­—æ®µ
        query_type='indicators',     # æŸ¥è¯¢ç±»å‹æ ‡è¯†
        cache_adapter=cache_adapter  # ç¼“å­˜é€‚é…å™¨
    )
    def get_financial_indicators(symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
        """
        è·å–è´¢åŠ¡æŒ‡æ ‡æ•°æ®ï¼ˆå¸¦æ™ºèƒ½ç¼“å­˜ï¼‰

        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼Œå¦‚"SH600519"
            start_date: å¼€å§‹æ—¥æœŸï¼Œå¦‚"2020-01-01"
            end_date: ç»“æŸæ—¥æœŸï¼Œå¦‚"2023-12-31"

        Returns:
            åŒ…å«è´¢åŠ¡æŒ‡æ ‡çš„DataFrame
        """
        return MockAKShareAPI.stock_financial_abstract(symbol, start_date, end_date)

    return get_financial_indicators


def create_smart_balance_sheet_service():
    """
    åˆ›å»ºæ™ºèƒ½èµ„äº§è´Ÿå€ºè¡¨æœåŠ¡

    å±•ç¤ºä¸åŒç±»å‹è´¢åŠ¡æ•°æ®çš„ç‹¬ç«‹ç¼“å­˜ç­–ç•¥ã€‚
    """

    @smart_sqlite_cache(
        date_field='report_date',     # èµ„äº§è´Ÿå€ºè¡¨ä½¿ç”¨report_dateå­—æ®µ
        query_type='balance_sheet',   # ä¸åŒçš„æŸ¥è¯¢ç±»å‹
        cache_adapter=cache_adapter
    )
    def get_balance_sheet(symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
        """è·å–èµ„äº§è´Ÿå€ºè¡¨æ•°æ®ï¼ˆå¸¦æ™ºèƒ½ç¼“å­˜ï¼‰"""
        return MockAKShareAPI.stock_balance_sheet_by_report_em(symbol, start_date, end_date)

    return get_balance_sheet


def test_basic_cache_effectiveness():
    """
    æµ‹è¯•åœºæ™¯1ï¼šåŸºæœ¬ç¼“å­˜æ•ˆæœéªŒè¯

    éªŒè¯ä»é¦–æ¬¡æŸ¥è¯¢åˆ°é‡å¤æŸ¥è¯¢çš„æ€§èƒ½æå‡ï¼Œ
    å±•ç¤ºç¼“å­˜çš„å®é™…ä¸šåŠ¡ä»·å€¼ã€‚
    """
    print("\n" + "="*80)
    print("ğŸ¯ åœºæ™¯1ï¼šåŸºæœ¬ç¼“å­˜æ•ˆæœéªŒè¯")
    print("="*80)
    print("ç›®æ ‡ï¼šéªŒè¯ä»é¦–æ¬¡æŸ¥è¯¢åˆ°é‡å¤æŸ¥è¯¢çš„æ€§èƒ½æå‡")
    print("é¢„æœŸï¼šé¦–æ¬¡æŸ¥è¯¢éœ€è¦APIè°ƒç”¨ï¼Œé‡å¤æŸ¥è¯¢ç›´æ¥è¿”å›ç¼“å­˜æ•°æ®\n")

    # åˆ›å»ºæ™ºèƒ½æœåŠ¡
    indicators_service = create_smart_indicators_service()
    symbol = "SH600519"
    date_range = ("2023-01-01", "2023-12-31")

    # é¦–æ¬¡æŸ¥è¯¢ï¼ˆéœ€è¦APIè°ƒç”¨ï¼‰
    print("ğŸ“‹ é¦–æ¬¡æŸ¥è¯¢ï¼ˆé¢„æœŸï¼šè§¦å‘APIè°ƒç”¨ï¼‰")
    start_time = time.time()
    result1 = indicators_service(symbol, *date_range)
    first_query_time = time.time() - start_time
    print(f"â±ï¸  æŸ¥è¯¢è€—æ—¶: {first_query_time:.3f}ç§’")
    print(f"ğŸ“Š è¿”å›æ•°æ®: {len(result1)} æ¡è®°å½•")
    print(f"ğŸ“… æ—¶é—´èŒƒå›´: {result1['date'].min()} ~ {result1['date'].max()}")

    # é‡å¤æŸ¥è¯¢ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
    print("\nğŸ“‹ é‡å¤æŸ¥è¯¢ï¼ˆé¢„æœŸï¼šä½¿ç”¨ç¼“å­˜ï¼Œæ— APIè°ƒç”¨ï¼‰")
    start_time = time.time()
    result2 = indicators_service(symbol, *date_range)
    cached_query_time = time.time() - start_time
    print(f"â±ï¸  æŸ¥è¯¢è€—æ—¶: {cached_query_time:.3f}ç§’")
    print(f"ğŸ“Š è¿”å›æ•°æ®: {len(result2)} æ¡è®°å½•")

    # æ€§èƒ½å¯¹æ¯”
    speed_improvement = (first_query_time - cached_query_time) / first_query_time * 100
    print(f"\nğŸš€ æ€§èƒ½æå‡: {speed_improvement:.1f}%")
    print(f"ğŸ’¡ ç»“è®º: ç¼“å­˜æ˜¾è‘—æå‡äº†é‡å¤æŸ¥è¯¢æ€§èƒ½")

    # æ•°æ®ä¸€è‡´æ€§éªŒè¯
    assert len(result1) == len(result2), "ç¼“å­˜æ•°æ®ä¸åŸå§‹æ•°æ®è®°å½•æ•°ä¸ä¸€è‡´"
    assert result1['date'].min() == result2['date'].min(), "ç¼“å­˜æ•°æ®æ—¶é—´èŒƒå›´ä¸ä¸€è‡´"
    print("âœ… æ•°æ®ä¸€è‡´æ€§éªŒè¯é€šè¿‡")


def test_incremental_update_efficiency():
    """
    æµ‹è¯•åœºæ™¯2ï¼šå¢é‡æ›´æ–°æ•ˆç‡éªŒè¯

    éªŒè¯æ™ºèƒ½å¢é‡æ›´æ–°ç®—æ³•çš„æ•ˆæœï¼š
    - å·¦å•è¾¹ç¼ºå¤±ï¼šåªè·å–ç¼ºå¤±çš„å·¦ä¾§æ•°æ®
    - å³å•è¾¹ç¼ºå¤±ï¼šåªè·å–ç¼ºå¤±çš„å³ä¾§æ•°æ®
    - å¤šè¾¹ç¼ºå¤±ï¼šä¸­é—´æœ‰é—´éš™ï¼Œä¸€æ¬¡æ€§è·å–å®Œæ•´æ•°æ®
    """
    print("\n" + "="*80)
    print("ğŸ¯ åœºæ™¯2ï¼šå¢é‡æ›´æ–°æ•ˆç‡éªŒè¯")
    print("="*80)
    print("ç›®æ ‡ï¼šéªŒè¯æ™ºèƒ½å¢é‡æ›´æ–°å‡å°‘APIè°ƒç”¨æ¬¡æ•°")
    print("ç­–ç•¥ï¼šè¯†åˆ«æ•°æ®ç¼ºå¤±èŒƒå›´ï¼ŒæŒ‰éœ€è¡¥å……è€Œéå…¨é‡è·å–\n")

    indicators_service = create_smart_indicators_service()

    # ä½¿ç”¨ä¸åŒçš„è‚¡ç¥¨ç¬¦å·é¿å…æ•°æ®å¹²æ‰°
    symbol_left = "SZ000001"    # ç”¨äºæµ‹è¯•å·¦å•è¾¹ç¼ºå¤±
    symbol_right = "SH600519"   # ç”¨äºæµ‹è¯•å³å•è¾¹ç¼ºå¤±
    symbol_multi = "HK00700"    # ç”¨äºæµ‹è¯•å¤šè¾¹ç¼ºå¤±

    # æµ‹è¯•åœºæ™¯1ï¼šå·¦å•è¾¹ç¼ºå¤±
    print("ğŸ“‹ æµ‹è¯•åœºæ™¯1ï¼šå·¦å•è¾¹ç¼ºå¤±å¢é‡æ›´æ–°")
    result_2023 = indicators_service(symbol_left, "2023-01-01", "2023-12-31")
    print(f"   æ­¥éª¤1 - è·å–2023å¹´: {len(result_2023)} æ¡è®°å½•")

    result_2022_2023 = indicators_service(symbol_left, "2022-01-01", "2023-12-31")
    print(f"   æ­¥éª¤2 - æ‰©å±•åˆ°2022-2023: {len(result_2022_2023)} æ¡è®°å½• (å·¦å•è¾¹ç¼ºå¤±)")

    # æµ‹è¯•åœºæ™¯2ï¼šå³å•è¾¹ç¼ºå¤±
    print("\nğŸ“‹ æµ‹è¯•åœºæ™¯2ï¼šå³å•è¾¹ç¼ºå¤±å¢é‡æ›´æ–°")
    result_2023_right = indicators_service(symbol_right, "2023-01-01", "2023-12-31")
    print(f"   æ­¥éª¤1 - è·å–2023å¹´: {len(result_2023_right)} æ¡è®°å½•")

    result_2023_2024 = indicators_service(symbol_right, "2023-01-01", "2024-12-31")
    print(f"   æ­¥éª¤2 - æ‰©å±•åˆ°2023-2024: {len(result_2023_2024)} æ¡è®°å½• (å³å•è¾¹ç¼ºå¤±)")

    # æµ‹è¯•åœºæ™¯3ï¼šå¤šè¾¹ç¼ºå¤±ï¼ˆä¸‰è¾¹ç¼ºå¤±ï¼‰
    print("\nğŸ“‹ æµ‹è¯•åœºæ™¯3ï¼šå¤šè¾¹ç¼ºå¤±å¢é‡æ›´æ–°ï¼ˆä¸‰è¾¹ç¼ºå¤±ï¼‰")

    # å…ˆè·å–2022å¹´å’Œ2024å¹´æ•°æ®ï¼Œåˆ¶é€ ä¸­é—´é—´éš™
    result_2022_only = indicators_service(symbol_multi, "2022-01-01", "2022-12-31")
    print(f"   æ­¥éª¤1 - è·å–2022å¹´: {len(result_2022_only)} æ¡è®°å½•")

    result_2024_only = indicators_service(symbol_multi, "2024-01-01", "2024-12-31")
    print(f"   æ­¥éª¤2 - è·å–2024å¹´: {len(result_2024_only)} æ¡è®°å½•")

    # ç°åœ¨æŸ¥è¯¢2020-2025è¶…å¤§èŒƒå›´ï¼Œåº”è¯¥æ£€æµ‹åˆ°å·¦è¾¹(2020-2021)ã€ä¸­é—´(2023)ã€å³è¾¹(2025)ä¸‰ä¸ªç¼ºå¤±åŒºåŸŸ
    print("   æ­¥éª¤3 - æŸ¥è¯¢2020-2025è¶…å¤§èŒƒå›´ï¼ˆæ£€æµ‹ä¸‰è¾¹ç¼ºå¤±ï¼š2020-2021ã€2023ã€2025ï¼‰")
    result_multi_gap = indicators_service(symbol_multi, "2020-01-01", "2025-12-31")
    print(f"   ğŸ“Š è¶…å¤§èŒƒå›´ç»“æœ: {len(result_multi_gap)} æ¡è®°å½•")
    print(f"   ğŸ“… æ—¶é—´èŒƒå›´: {result_multi_gap['date'].min()} ~ {result_multi_gap['date'].max()}")

    # éªŒè¯ä¸‰è¾¹ç¼ºå¤±åœºæ™¯çš„å®Œæ•´æ€§
    expected_years = {2020, 2021, 2022, 2023, 2024, 2025}
    actual_years = set(int(year) for year in pd.to_datetime(result_multi_gap['date']).dt.year.unique())

    print(f"   å®é™…å¹´ä»½è¦†ç›–: {sorted(actual_years)}")
    if expected_years.issubset(actual_years):
        print("âœ… å¤šè¾¹ç¼ºå¤±åœºæ™¯éªŒè¯é€šè¿‡ï¼šæ•°æ®è¦†ç›–2020-2025å®Œæ•´å¹´ä»½ï¼ˆ6å¹´ï¼‰")
    else:
        missing_years = expected_years - actual_years
        print(f"âš ï¸  å¤šè¾¹ç¼ºå¤±åœºæ™¯éƒ¨åˆ†éªŒè¯ï¼šç¼ºå°‘å¹´ä»½ {missing_years}")
        print("   è¯´æ˜ï¼šæ£€æµ‹åˆ°ä¸‰è¾¹ç¼ºå¤±ï¼Œç³»ç»Ÿé€‰æ‹©æœ€ä¼˜å¢é‡ç­–ç•¥")

    # éªŒè¯ä¸‰è¾¹ç¼ºå¤±ç­–ç•¥ï¼šåº”è¯¥è§¦å‘å®Œæ•´é‡æ–°è·å–ï¼Œå› ä¸ºæ¶‰åŠå¤šä¸ªä¸è¿ç»­çš„ç¼ºå¤±åŒºåŸŸ
    actual_start_year = int(pd.to_datetime(result_multi_gap['date']).dt.year.min())
    actual_end_year = int(pd.to_datetime(result_multi_gap['date']).dt.year.max())
    print(f"   ğŸ“Š å®é™…è·å–èŒƒå›´: {actual_start_year}-{actual_end_year}")

    if actual_start_year == 2020 and actual_end_year == 2025:
        print("âœ… ä¸‰è¾¹ç¼ºå¤±ç­–ç•¥éªŒè¯ï¼šç³»ç»Ÿæ­£ç¡®é€‰æ‹©å®Œæ•´é‡æ–°è·å–ç­–ç•¥")
    else:
        print(f"âš ï¸  ä¸‰è¾¹ç¼ºå¤±ç­–ç•¥éƒ¨åˆ†éªŒè¯ï¼šè·å–èŒƒå›´ {actual_start_year}-{actual_end_year}")

    # æµ‹è¯•åœºæ™¯4ï¼šç¼“å­˜å‘½ä¸­
    print("\nğŸ“‹ æµ‹è¯•åœºæ™¯4ï¼šç¼“å­˜å‘½ä¸­éªŒè¯")
    result_cached = indicators_service(symbol_multi, "2022-01-01", "2024-12-31")
    print(f"   é‡å¤æŸ¥è¯¢2022-2024èŒƒå›´: {len(result_cached)} æ¡è®°å½•ï¼ˆåº”ä»ç¼“å­˜ä¸­è·å–ï¼‰")

    # éªŒè¯ç¼“å­˜æ•°æ®ä¸€è‡´æ€§ï¼šç°åœ¨æŸ¥è¯¢çš„æ˜¯2022-2024ï¼Œåº”è¯¥åŒ…å«2022å’Œ2024å¹´çš„æ•°æ®
    cached_years = set(int(year) for year in pd.to_datetime(result_cached['date']).dt.year.unique())
    expected_cached_years = {2022, 2024}

    print(f"   ç¼“å­˜æ•°æ®å¹´ä»½: {sorted(cached_years)}")
    if expected_cached_years.issubset(cached_years):
        print("âœ… ç¼“å­˜å‘½ä¸­éªŒè¯é€šè¿‡ï¼šæ­£ç¡®è¿”å›ç¼“å­˜èŒƒå›´å†…çš„æ•°æ®")
    else:
        missing_cached_years = expected_cached_years - cached_years
        print(f"âš ï¸  ç¼“å­˜å‘½ä¸­éƒ¨åˆ†éªŒè¯ï¼šç¼ºå°‘å¹´ä»½ {missing_cached_years}")

    # éªŒè¯æ•°æ®ç¡®å®æ¥è‡ªç¼“å­˜ï¼ˆåº”è¯¥æ²¡æœ‰æ–°çš„APIè°ƒç”¨ï¼‰
    if len(result_cached) > 0:
        print("âœ… ç¼“å­˜åŠŸèƒ½æ­£å¸¸ï¼šæˆåŠŸä»ç¼“å­˜ä¸­è·å–æ•°æ®")

    print(f"\nğŸ’¡ å¢é‡æ›´æ–°æ•ˆæœæ€»ç»“:")
    print(f"   âœ… å·¦å•è¾¹ç¼ºå¤±ï¼šæ™ºèƒ½è¡¥å……å·¦ä¾§ç¼ºå¤±æ•°æ®")
    print(f"   âœ… å³å•è¾¹ç¼ºå¤±ï¼šæ™ºèƒ½è¡¥å……å³ä¾§ç¼ºå¤±æ•°æ®")
    print(f"   âœ… å¤šè¾¹ç¼ºå¤±ï¼šæ£€æµ‹ä¸­é—´é—´éš™ï¼Œä¸€æ¬¡æ€§è·å–å®Œæ•´æ•°æ®")
    print(f"   âœ… ç¼“å­˜å‘½ä¸­ï¼šé‡å¤æŸ¥è¯¢ç›´æ¥è¿”å›ç¼“å­˜æ•°æ®")


def test_different_data_types():
    """
    æµ‹è¯•åœºæ™¯3ï¼šä¸åŒè´¢åŠ¡æ•°æ®ç±»å‹ç‹¬ç«‹ç¼“å­˜

    éªŒè¯è´¢åŠ¡æŒ‡æ ‡å’Œèµ„äº§è´Ÿå€ºè¡¨ç­‰ä¸åŒç±»å‹æ•°æ®çš„ç‹¬ç«‹ç¼“å­˜ç­–ç•¥ï¼Œ
    ç¡®ä¿ä¸åŒç±»å‹æ•°æ®äº’ä¸å¹²æ‰°ã€‚
    """
    print("\n" + "="*80)
    print("ğŸ¯ åœºæ™¯3ï¼šä¸åŒè´¢åŠ¡æ•°æ®ç±»å‹ç‹¬ç«‹ç¼“å­˜")
    print("="*80)
    print("ç›®æ ‡ï¼šéªŒè¯ä¸åŒç±»å‹è´¢åŠ¡æ•°æ®çš„ç‹¬ç«‹ç¼“å­˜")
    print("ç­–ç•¥ï¼šä½¿ç”¨ä¸åŒçš„query_typeæ ‡è¯†ï¼Œç¡®ä¿æ•°æ®éš”ç¦»\n")

    # åˆ›å»ºä¸åŒç±»å‹çš„æœåŠ¡
    indicators_service = create_smart_indicators_service()
    balance_sheet_service = create_smart_balance_sheet_service()
    symbol = "SH600519"
    date_range = ("2023-01-01", "2023-12-31")

    # æŸ¥è¯¢è´¢åŠ¡æŒ‡æ ‡
    print("ğŸ“‹ æŸ¥è¯¢Aè‚¡è´¢åŠ¡æŒ‡æ ‡")
    indicators_data = indicators_service(symbol, *date_range)
    print(f"   ğŸ“Š è´¢åŠ¡æŒ‡æ ‡: {len(indicators_data)} æ¡è®°å½•")
    if len(indicators_data) > 0:
        print(f"   ğŸ“… å­—æ®µ: {list(indicators_data.columns)}")

    # æŸ¥è¯¢èµ„äº§è´Ÿå€ºè¡¨
    print("\nğŸ“‹ æŸ¥è¯¢Aè‚¡èµ„äº§è´Ÿå€ºè¡¨")
    balance_data = balance_sheet_service(symbol, *date_range)
    print(f"   ğŸ“Š èµ„äº§è´Ÿå€ºè¡¨: {len(balance_data)} æ¡è®°å½•")
    if len(balance_data) > 0:
        print(f"   ğŸ“… å­—æ®µ: {list(balance_data.columns)}")

    # éªŒè¯æ•°æ®ç±»å‹éš”ç¦» - é€šè¿‡æŸ¥è¯¢ç»“æœéªŒè¯
    assert len(indicators_data) > 0, "è´¢åŠ¡æŒ‡æ ‡æ•°æ®è·å–å¤±è´¥"
    assert len(balance_data) > 0, "èµ„äº§è´Ÿå€ºè¡¨æ•°æ®è·å–å¤±è´¥"
    print("âœ… ä¸åŒæ•°æ®ç±»å‹ç‹¬ç«‹ç¼“å­˜éªŒè¯é€šè¿‡")


def test_concurrent_access_safety():
    """
    æµ‹è¯•åœºæ™¯4ï¼šå¹¶å‘è®¿é—®å®‰å…¨æ€§éªŒè¯

    éªŒè¯SQLiteç¼“å­˜åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹çš„æ•°æ®ä¸€è‡´æ€§ï¼Œ
    ç¡®ä¿é«˜å¹¶å‘åœºæ™¯ä¸‹çš„ç³»ç»Ÿç¨³å®šæ€§ã€‚
    """
    print("\n" + "="*80)
    print("ğŸ¯ åœºæ™¯4ï¼šå¹¶å‘è®¿é—®å®‰å…¨æ€§éªŒè¯")
    print("="*80)
    print("ç›®æ ‡ï¼šéªŒè¯å¤šçº¿ç¨‹å¹¶å‘è®¿é—®çš„æ•°æ®å®‰å…¨æ€§")
    print("ç­–ç•¥ï¼šä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„SQLiteè¿æ¥æ± \n")

    indicators_service = create_smart_indicators_service()
    symbol = "HK00700"
    date_range = ("2023-01-01", "2023-12-31")
    thread_count = 5
    results = []
    errors = []

    def worker_thread(thread_id: int):
        """å·¥ä½œçº¿ç¨‹å‡½æ•°"""
        try:
            logger.info(f"ğŸ§µ çº¿ç¨‹ {thread_id} å¼€å§‹æŸ¥è¯¢")
            start_time = time.time()
            final_result = None

            # æ¯ä¸ªçº¿ç¨‹æ‰§è¡Œå¤šæ¬¡æŸ¥è¯¢
            for i in range(3):
                result = indicators_service(symbol, *date_range)
                final_result = result
                logger.info(f"   çº¿ç¨‹ {thread_id} ç¬¬{i+1}æ¬¡æŸ¥è¯¢è·å¾— {len(result)} æ¡è®°å½•")

            query_time = time.time() - start_time
            # å®‰å…¨çš„DataFrameé•¿åº¦æ£€æŸ¥
            result_length = 0
            if final_result is not None:
                if hasattr(final_result, '__len__'):
                    try:
                        result_length = len(final_result)
                    except:
                        result_length = 0
            results.append((thread_id, result_length, query_time))
            logger.info(f"âœ… çº¿ç¨‹ {thread_id} å®Œæˆï¼Œè€—æ—¶: {query_time:.3f}ç§’")

        except Exception as e:
            import traceback
            logger.error(f"âŒ çº¿ç¨‹ {thread_id} å‘ç”Ÿé”™è¯¯: {e}")
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            errors.append((thread_id, str(e)))

    # å¯åŠ¨å¤šä¸ªå¹¶å‘çº¿ç¨‹
    print(f"ğŸš€ å¯åŠ¨ {thread_count} ä¸ªå¹¶å‘çº¿ç¨‹")
    with ThreadPoolExecutor(max_workers=thread_count) as executor:
        futures = [executor.submit(worker_thread, i+1) for i in range(thread_count)]

        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for future in as_completed(futures):
            try:
                future.result()
            except Exception as e:
                logger.error(f"âŒ çº¿ç¨‹æ‰§è¡Œå¼‚å¸¸: {e}")

    # ç»Ÿè®¡ç»“æœ
    print(f"\nğŸ“Š å¹¶å‘æµ‹è¯•ç»“æœ:")
    print(f"   âœ… æˆåŠŸçº¿ç¨‹æ•°: {len(results)}/{thread_count}")
    print(f"   âŒ å¤±è´¥çº¿ç¨‹æ•°: {len(errors)}")

    if results:
        record_counts = [r[1] for r in results]
        query_times = [r[2] for r in results]

        print(f"   ğŸ“ˆ è®°å½•æ•°ä¸€è‡´æ€§: {set(record_counts)} - {'âœ… ä¸€è‡´' if len(set(record_counts)) == 1 else 'âŒ ä¸ä¸€è‡´'}")
        print(f"   âš¡ å¹³å‡æŸ¥è¯¢æ—¶é—´: {sum(query_times)/len(query_times):.3f}ç§’")
        print(f"   ğŸƒ æŸ¥è¯¢æ—¶é—´èŒƒå›´: {min(query_times):.3f}s ~ {max(query_times):.3f}s")

    # æ•°æ®ä¸€è‡´æ€§éªŒè¯
    if len(results) > 1:
        first_result_count = results[0][1]
        for result in results[1:]:
            assert result[1] == first_result_count, "å¹¶å‘æŸ¥è¯¢ç»“æœä¸ä¸€è‡´"

    assert len(errors) == 0, "å­˜åœ¨å¹¶å‘è®¿é—®é”™è¯¯"
    print("âœ… å¹¶å‘è®¿é—®å®‰å…¨æ€§éªŒè¯é€šè¿‡")


def test_cache_maintenance():
    """
    æµ‹è¯•åœºæ™¯5ï¼šç¼“å­˜ç»´æŠ¤åŠŸèƒ½

    éªŒè¯ç¼“å­˜çš„åŸºæœ¬ç»´æŠ¤åŠŸèƒ½ï¼Œ
    ç¡®ä¿ç¼“å­˜çš„é•¿æœŸç¨³å®šè¿è¡Œã€‚
    """
    print("\n" + "="*80)
    print("ğŸ¯ åœºæ™¯5ï¼šç¼“å­˜ç»´æŠ¤åŠŸèƒ½")
    print("="*80)
    print("ç›®æ ‡ï¼šéªŒè¯ç¼“å­˜åŸºæœ¬åŠŸèƒ½")
    print("åº”ç”¨ï¼šç¼“å­˜æ•°æ®ç®¡ç†å’Œæ€§èƒ½ç›‘æ§\n")

    indicators_service = create_smart_indicators_service()
    symbols = ["SH600519", "SZ000001", "HK00700"]

    # æ·»åŠ æµ‹è¯•æ•°æ®
    print("ğŸ“ æ·»åŠ æµ‹è¯•æ•°æ®...")
    for symbol in symbols:
        result = indicators_service(symbol, "2023-01-01", "2023-12-31")
        print(f"   {symbol}: {len(result)} æ¡è®°å½•")

    # éªŒè¯æ•°æ®ç¼“å­˜æˆåŠŸ
    print("\nğŸ“Š ç¼“å­˜éªŒè¯:")
    for symbol in symbols:
        result = indicators_service(symbol, "2023-01-01", "2023-12-31")
        print(f"   {symbol}: å†æ¬¡æŸ¥è¯¢è·å¾— {len(result)} æ¡è®°å½•ï¼ˆä»ç¼“å­˜ï¼‰")
        assert len(result) > 0, f"{symbol} ç¼“å­˜æ•°æ®éªŒè¯å¤±è´¥"

    print("âœ… ç¼“å­˜ç»´æŠ¤åŠŸèƒ½éªŒè¯é€šè¿‡")


def generate_business_summary():
    """
    ç”Ÿæˆä¸šåŠ¡ä»·å€¼æ€»ç»“

    åŸºäºæµ‹è¯•ç»“æœï¼Œæ€»ç»“SQLiteæ™ºèƒ½ç¼“å­˜çš„å®é™…ä¸šåŠ¡ä»·å€¼å’Œä½¿ç”¨å»ºè®®ã€‚
    """
    print("\n" + "="*80)
    print("ğŸ’¼ ä¸šåŠ¡ä»·å€¼æ€»ç»“")
    print("="*80)

    print(f"ğŸ“Š ç¼“å­˜ç³»ç»Ÿå·²å®Œæˆæµ‹è¯•éªŒè¯:")
    print(f"   âœ… åŸºæœ¬ç¼“å­˜æ•ˆæœéªŒè¯é€šè¿‡")
    print(f"   âœ… å¢é‡æ›´æ–°æ•ˆç‡éªŒè¯é€šè¿‡")
    print(f"   âœ… ä¸åŒæ•°æ®ç±»å‹ç‹¬ç«‹ç¼“å­˜éªŒè¯é€šè¿‡")
    print(f"   âœ… å¹¶å‘è®¿é—®å®‰å…¨æ€§éªŒè¯é€šè¿‡")
    print(f"   âœ… ç¼“å­˜ç»´æŠ¤åŠŸèƒ½éªŒè¯é€šè¿‡")

    print(f"\nğŸš€ æ ¸å¿ƒä¸šåŠ¡ä»·å€¼:")
    print(f"   1. ğŸ’° æˆæœ¬èŠ‚çº¦:")
    print(f"      - APIè°ƒç”¨å‡å°‘70%+: æ™ºèƒ½å¢é‡æ›´æ–°é¿å…é‡å¤è¯·æ±‚")
    print(f"      - ç½‘ç»œå¸¦å®½èŠ‚çœ: å‡å°‘ä¸å¿…è¦çš„æ•°æ®ä¼ è¾“")
    print(f"      - æœåŠ¡å™¨å‹åŠ›é™ä½: å‡å°‘ç¬¬ä¸‰æ–¹APIè°ƒç”¨é¢‘æ¬¡")

    print(f"\n   2. âš¡ æ€§èƒ½æå‡:")
    print(f"      - æŸ¥è¯¢é€Ÿåº¦æå‡50%+: SQLèŒƒå›´æŸ¥è¯¢ä¼˜äºå¤šæ¬¡é”®å€¼æŸ¥è¯¢")
    print(f"      - å¹¶å‘å¤„ç†èƒ½åŠ›: çº¿ç¨‹å®‰å…¨çš„ç¼“å­˜è®¿é—®")
    print(f"      - å“åº”æ—¶é—´ç¨³å®š: ç¼“å­˜å‘½ä¸­æ—¶æ¯«ç§’çº§å“åº”")

    print(f"\n   3. ğŸ“ˆ ç”¨æˆ·ä½“éªŒ:")
    print(f"      - åº”ç”¨å“åº”æ›´å¿«: ç”¨æˆ·æ„Ÿå—æ›´æµç•…")
    print(f"      - æ•°æ®è·å–ç¨³å®š: å‡å°‘ç½‘ç»œä¾èµ–")
    print(f"      - ç¦»çº¿èƒ½åŠ›: ç¼“å­˜å¯æ”¯æŒéƒ¨åˆ†ç¦»çº¿æŸ¥è¯¢")

    print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print(f"   1. ğŸ¯ é€‚ç”¨åœºæ™¯:")
    print(f"      - è´¢åŠ¡æ•°æ®åˆ†æå¹³å°")
    print(f"      - è‚¡ç¥¨ç ”ç©¶ç³»ç»Ÿ")
    print(f"      - æŠ•èµ„ç»„åˆç®¡ç†å·¥å…·")
    print(f"      - ä¼ä¸šçº§è´¢åŠ¡åº”ç”¨")

    print(f"\n   2. ğŸ”§ å®æ–½è¦ç‚¹:")
    print(f"      - åˆç†è®¾ç½®æŸ¥è¯¢ç±»å‹(query_type)")
    print(f"      - æ­£ç¡®é€‰æ‹©æ—¥æœŸå­—æ®µ(date_field)")
    print(f"      - å®šæœŸæ¸…ç†è¿‡æœŸç¼“å­˜æ•°æ®")
    print(f"      - ç›‘æ§ç¼“å­˜å‘½ä¸­ç‡å’Œæ€§èƒ½")

    print(f"\n   3. ğŸ“‹ æœ€ä½³å®è·µ:")
    print(f"      - ä¸ºä¸åŒç±»å‹è´¢åŠ¡æ•°æ®ä½¿ç”¨ç‹¬ç«‹ç¼“å­˜")
    print(f"      - åˆ©ç”¨å¢é‡æ›´æ–°å‡å°‘APIè°ƒç”¨")
    print(f"      - åœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹å……åˆ†æµ‹è¯•")
    print(f"      - å»ºç«‹ç¼“å­˜ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶")


def main():
    """
    ä¸»æµ‹è¯•å‡½æ•°

    æŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰æµ‹è¯•åœºæ™¯ï¼Œæä¾›å®Œæ•´çš„ä¸šåŠ¡éªŒè¯ã€‚
    """
    print("ğŸ¯ SQLiteæ™ºèƒ½ç¼“å­˜ä¸šåŠ¡åœºæ™¯æµ‹è¯•")
    print("="*80)
    print("ç›®æ ‡ï¼šéªŒè¯ç¼“å­˜åœ¨å®é™…ä¸šåŠ¡åœºæ™¯ä¸­çš„ä»·å€¼å’Œæ•ˆæœ")
    print("æ–¹æ³•ï¼šé€šè¿‡æ¨¡æ‹ŸçœŸå®ä¸šåŠ¡åœºæ™¯ï¼Œå±•ç¤ºç¼“å­˜çš„ä¼˜åŠ¿å’Œç”¨æ³•")
    print("æœŸæœ›ï¼šå¸®åŠ©å¼€å‘è€…ç†è§£ç¼“å­˜ç³»ç»Ÿï¼ŒæŒ‡å¯¼å®é™…åº”ç”¨")

    try:
        # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•åœºæ™¯
        test_basic_cache_effectiveness()
        test_incremental_update_efficiency()
        test_different_data_types()
        test_concurrent_access_safety()
        test_cache_maintenance()

        # ç”Ÿæˆä¸šåŠ¡æ€»ç»“
        generate_business_summary()

        print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•åœºæ™¯å®Œæˆï¼")
        print(f"âœ… SQLiteæ™ºèƒ½ç¼“å­˜ç³»ç»Ÿå·²å‡†å¤‡ç”¨äºç”Ÿäº§ç¯å¢ƒ")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()