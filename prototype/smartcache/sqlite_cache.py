"""
SQLiteæ™ºèƒ½ç¼“å­˜

ç”Ÿäº§çº§SQLiteç¼“å­˜å®ç°ï¼Œæ”¯æŒï¼š
1. æŒ‰æ¡ç¼“å­˜å’Œæ—¥æœŸèŒƒå›´æŸ¥è¯¢
2. æ™ºèƒ½å¢é‡æ›´æ–°
3. å¤šæ—¥æœŸå­—æ®µæ”¯æŒ
4. çº¿ç¨‹å®‰å…¨è®¿é—®
"""

import sqlite3
import json
import os
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, timedelta
import logging
import threading

logger = logging.getLogger(__name__)


class SQLiteCache:
    """
    SQLiteæ™ºèƒ½ç¼“å­˜

    æ ¸å¿ƒç‰¹æ€§ï¼š
    1. æŒ‰æ¡ç¼“å­˜ï¼šæ¯æ¡è´¢åŠ¡æ•°æ®ç‹¬ç«‹å­˜å‚¨ï¼Œä¾¿äºç²¾ç¡®ç®¡ç†
    2. æ—¥æœŸèŒƒå›´æŸ¥è¯¢ï¼šåˆ©ç”¨SQL BETWEENå®ç°é«˜æ•ˆèŒƒå›´ç­›é€‰
    3. æ™ºèƒ½å¢é‡æ›´æ–°ï¼šè‡ªåŠ¨è¯†åˆ«ç¼ºå¤±æ•°æ®ï¼Œé¿å…é‡å¤APIè°ƒç”¨
    4. çº¿ç¨‹å®‰å…¨ï¼šæ”¯æŒå¹¶å‘è®¿é—®
    """

    def __init__(self, db_path: str = "cache/financial_data.db"):
        """
        åˆå§‹åŒ–SQLiteç¼“å­˜

        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        self.db_path = db_path
        self._local = threading.local()

        # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(db_path), exist_ok=True)

        # åˆå§‹åŒ–æ•°æ®åº“
        self._init_database()

        logger.debug(f"SQLiteç¼“å­˜åˆå§‹åŒ–å®Œæˆ: {db_path}")

    def _init_database(self) -> None:
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨å’Œç´¢å¼•"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            # åˆ›å»ºä¸»è¡¨ - ç®€åŒ–è®¾è®¡ï¼Œå»é™¤å†—ä½™å­—æ®µ
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS financial_data (
                    cache_key TEXT PRIMARY KEY,    -- å”¯ä¸€é”®ï¼šsymbol_date
                    symbol TEXT NOT NULL,          -- è‚¡ç¥¨ä»£ç ï¼ˆå·²åŒ…å«å¸‚åœºä¿¡æ¯ï¼‰
                    date_value TEXT NOT NULL,      -- æ ‡å‡†åŒ–æ—¥æœŸå€¼
                    date_field TEXT NOT NULL,      -- åŸå§‹æ—¥æœŸå­—æ®µåï¼ˆdate/report_date/end_dateï¼‰
                    query_type TEXT NOT NULL,      -- æŸ¥è¯¢ç±»å‹ï¼ˆindicators/profit/balance/cashflowï¼‰
                    data_json TEXT NOT NULL,       -- å®Œæ•´åŸå§‹æ•°æ®JSON
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)

            # åˆ›å»ºé«˜æ•ˆç´¢å¼• - æ”¯æŒå„ç§æŸ¥è¯¢æ¨¡å¼
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_symbol_date ON financial_data(symbol, date_value)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_symbol_type_date ON financial_data(symbol, query_type, date_value)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_date_field ON financial_data(date_field)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_query_type ON financial_data(query_type)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_created_at ON financial_data(created_at)")

            conn.commit()

    def _get_connection(self) -> sqlite3.Connection:
        """è·å–çº¿ç¨‹å®‰å…¨çš„æ•°æ®åº“è¿æ¥"""
        if not hasattr(self._local, 'connection'):
            self._local.connection = sqlite3.connect(self.db_path)
        return self._local.connection

    def save_records(self, symbol: str, records: List[Dict[str, Any]],
                    date_field: str, query_type: str) -> int:
        """
        æŒ‰æ¡ä¿å­˜è´¢åŠ¡è®°å½•

        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚SH600519ã€00700ã€AAPLï¼‰
            records: è´¢åŠ¡æ•°æ®è®°å½•åˆ—è¡¨
            date_field: æ—¥æœŸå­—æ®µåï¼ˆdate/report_date/end_dateï¼‰
            query_type: æŸ¥è¯¢ç±»å‹ï¼ˆindicators/profit/balance/cashflowï¼‰

        Returns:
            å®é™…ä¿å­˜çš„è®°å½•æ•°é‡
        """
        if records is None or (hasattr(records, 'empty') and records.empty):
            return 0

        # å¦‚æœæ˜¯DataFrameï¼Œè½¬æ¢ä¸ºè®°å½•åˆ—è¡¨
        if hasattr(records, 'to_dict'):
            records = records.to_dict('records')

        saved_count = 0
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            for record in records:
                # æ£€æŸ¥å¿…éœ€çš„æ—¥æœŸå­—æ®µ
                if date_field not in record:
                    logger.warning(f"è®°å½•ç¼ºå°‘æ—¥æœŸå­—æ®µ {date_field}: {record}")
                    continue

                # ç”Ÿæˆç¼“å­˜é”® - ç®€åŒ–è®¾è®¡ï¼ŒåŸºäºè‚¡ç¥¨ä»£ç å’Œæ—¥æœŸ
                cache_key = f"{symbol}_{record[date_field]}_{query_type}"

                # åºåˆ—åŒ–å®Œæ•´æ•°æ®
                data_json = json.dumps(record, ensure_ascii=False)

                # ä½¿ç”¨UPSERTï¼šå­˜åœ¨åˆ™æ›´æ–°ï¼Œä¸å­˜åœ¨åˆ™æ’å…¥
                cursor.execute("""
                    INSERT INTO financial_data
                    (cache_key, symbol, date_value, date_field, query_type, data_json, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                    ON CONFLICT(cache_key) DO UPDATE SET
                        data_json = excluded.data_json,
                        updated_at = CURRENT_TIMESTAMP
                """, (cache_key, symbol, record[date_field], date_field, query_type, data_json))

                saved_count += 1

            conn.commit()
            if saved_count > 0:
                logger.info(f"ğŸ’¾ ä¿å­˜ {saved_count} æ¡è®°å½•åˆ°ç¼“å­˜: {symbol} - {query_type}")

        except Exception as e:
            conn.rollback()
            logger.error(f"ä¿å­˜ç¼“å­˜è®°å½•å¤±è´¥: {e}")
            raise

        return saved_count

    def query_by_date_range(self, symbol: str, start_date: str, end_date: str,
                           date_field: str, query_type: str) -> List[Dict[str, Any]]:
        """
        æŒ‰æ—¥æœŸèŒƒå›´æŸ¥è¯¢ç¼“å­˜æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            date_field: æ—¥æœŸå­—æ®µå
            query_type: æŸ¥è¯¢ç±»å‹

        Returns:
            åŒ¹é…çš„è®°å½•åˆ—è¡¨
        """
        conn = self._get_connection()
        cursor = conn.cursor()

        cursor.execute("""
            SELECT data_json FROM financial_data
            WHERE symbol = ?
              AND date_field = ?
              AND query_type = ?
              AND date_value BETWEEN ? AND ?
            ORDER BY date_value
        """, (symbol, date_field, query_type, start_date, end_date))

        rows = cursor.fetchall()
        if not rows:
            return []

        # è§£æJSONæ•°æ®
        results = [json.loads(row[0]) for row in rows]

        if results:
            logger.debug(f"ç¼“å­˜å‘½ä¸­: {symbol} {query_type} {start_date}-{end_date} ({len(results)}æ¡)")
        else:
            logger.debug(f"ç¼“å­˜æœªå‘½ä¸­: {symbol} {query_type} {start_date}-{end_date}")

        return results

    def _get_missing_date_ranges(self, symbol: str, start_date: str, end_date: str,
                            date_field: str, query_type: str) -> List[Dict[str, str]]:
        """
        å†…éƒ¨æ–¹æ³•ï¼šè·å–ç¼ºå¤±çš„æ—¥æœŸèŒƒå›´ï¼Œç”¨äºå¢é‡æ›´æ–°

        è®¾è®¡åŸåˆ™ï¼š
        1. å¦‚æœæœ‰ç¼ºå¤±æ•°æ®ï¼Œåˆå¹¶ä¸ºå•ä¸ªå®Œæ•´æ—¶é—´æ®µ
        2. ä¼˜åŒ–ç½‘ç»œå¼€é”€ï¼Œå‡å°‘APIè°ƒç”¨æ¬¡æ•°
        3. ç®€åŒ–å®ç°å’Œé”™è¯¯å¤„ç†

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            date_field: æ—¥æœŸå­—æ®µå
            query_type: æŸ¥è¯¢ç±»å‹

        Returns:
            ç©ºåˆ—è¡¨ï¼ˆå®Œå…¨ç¼“å­˜ï¼‰æˆ–å•ä¸ªåˆå¹¶èŒƒå›´ [{'start': '2020-01-01', 'end': '2025-12-31'}]
        """
        conn = self._get_connection()
        cursor = conn.cursor()

        cursor.execute("""
            SELECT date_value FROM financial_data
            WHERE symbol = ?
              AND date_field = ?
              AND query_type = ?
              AND date_value BETWEEN ? AND ?
            ORDER BY date_value
        """, (symbol, date_field, query_type, start_date, end_date))

        cached_dates = sorted([row[0] for row in cursor.fetchall()])

        if not cached_dates:
            # å®Œå…¨æ²¡æœ‰ç¼“å­˜æ•°æ®ï¼Œè¿”å›æ•´ä¸ªèŒƒå›´
            return [{'start': start_date, 'end': end_date}]

        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å®Œæ•´è¦†ç›–æ•´ä¸ªæ—¶é—´èŒƒå›´
        first_cached = cached_dates[0]
        last_cached = cached_dates[-1]

        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•ç¼ºå¤±
        has_gaps = False
        has_start_gap = first_cached > start_date
        has_end_gap = last_cached < end_date
        has_middle_gaps = False

        if has_start_gap:
            has_gaps = True
        elif has_end_gap:
            has_gaps = True
        else:
            # æ£€æŸ¥ä¸­é—´æ˜¯å¦æœ‰é—´éš™
            for i in range(len(cached_dates) - 1):
                current_date = cached_dates[i]
                next_cached_date = cached_dates[i + 1]
                next_expected_date = self._get_next_quarter(current_date)
                if next_expected_date < next_cached_date:
                    has_middle_gaps = True
                    has_gaps = True
                    break

        if has_gaps:
            if has_middle_gaps or (has_start_gap and has_end_gap):
                # å¤šè¾¹ç¼ºå¤±ï¼šå®Œæ•´é‡æ–°è·å–
                logger.debug(f"æ£€æµ‹åˆ°å¤šè¾¹ç¼ºå¤±ï¼Œå°†è·å–å®Œæ•´æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
                return [{'start': start_date, 'end': end_date}]
            elif has_start_gap:
                # å·¦å•è¾¹ç¼ºå¤±ï¼šæŒ‰éœ€è¡¥å……
                logger.debug(f"æ£€æµ‹åˆ°å·¦å•è¾¹ç¼ºå¤±ï¼ŒæŒ‰éœ€è¡¥å……: {start_date} åˆ° {first_cached}")
                return [{'start': start_date, 'end': first_cached}]
            elif has_end_gap:
                # å³å•è¾¹ç¼ºå¤±ï¼šæŒ‰éœ€è¡¥å……
                logger.debug(f"æ£€æµ‹åˆ°å³å•è¾¹ç¼ºå¤±ï¼ŒæŒ‰éœ€è¡¥å……: {last_cached} åˆ° {end_date}")
                return [{'start': last_cached, 'end': end_date}]
            else:
                # ä¸­é—´æœ‰é—´éš™ï¼Œå®Œæ•´é‡æ–°è·å–
                logger.debug(f"æ£€æµ‹åˆ°ä¸­é—´é—´éš™ï¼Œå°†è·å–å®Œæ•´æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
                return [{'start': start_date, 'end': end_date}]
        else:
            # ç¼“å­˜å®Œå…¨è¦†ç›–ï¼Œæ— ç¼ºå¤±
            return []

    
    def _count_quarters_between(self, start_date: str, end_date: str) -> int:
        """è®¡ç®—ä¸¤ä¸ªæ—¥æœŸä¹‹é—´çš„å­£åº¦æ•°é‡"""
        from datetime import datetime
        start = datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.strptime(end_date, '%Y-%m-%d')

        years = end.year - start.year
        months = end.month - start.month
        total_months = years * 12 + months
        return max(1, (total_months + 2) // 3)  # å‘ä¸Šå–æ•´

    def _get_next_quarter(self, date_str: str) -> str:
        """è·å–ä¸‹ä¸€ä¸ªå­£åº¦æœ«æ—¥æœŸ"""
        year, month, day = map(int, date_str.split('-'))

        if month == 3:   # Q1 -> Q2
            return f"{year}-06-30"
        elif month == 6:  # Q2 -> Q3
            return f"{year}-09-30"
        elif month == 9:  # Q3 -> Q4
            return f"{year}-12-31"
        elif month == 12: # Q4 -> next year Q1
            return f"{year + 1}-03-31"
        else:
            # å¦‚æœä¸æ˜¯æ ‡å‡†å­£åº¦æœ«ï¼Œç®€å•åŠ 3ä¸ªæœˆ
            if month + 3 > 12:
                return f"{year + 1}-{month + 3 - 12:02d}-28"
            else:
                return f"{year}-{month + 3:02d}-28"

    def _get_previous_day(self, date_str: str) -> str:
        """è·å–å‰ä¸€å¤©"""
        from datetime import datetime, timedelta
        date = datetime.strptime(date_str, '%Y-%m-%d')
        previous_day = date - timedelta(days=1)
        return previous_day.strftime('%Y-%m-%d')

    
    def clear_cache_by_symbol(self, symbol: Optional[str] = None) -> int:
        """
        æ¸…ç†æŒ‡å®šè‚¡ç¥¨çš„ç¼“å­˜æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼Œå¦‚æœä¸ºNoneåˆ™æ¸…ç©ºæ‰€æœ‰æ•°æ®

        Returns:
            åˆ é™¤çš„è®°å½•æ•°é‡
        """
        conn = self._get_connection()
        cursor = conn.cursor()

        if symbol:
            cursor.execute("DELETE FROM financial_data WHERE symbol = ?", (symbol,))
            if cursor.rowcount > 0:
                logger.info(f"ğŸ—‘ï¸ æ¸…ç†äº†è‚¡ç¥¨ {symbol} çš„ {cursor.rowcount} æ¡ç¼“å­˜è®°å½•")
        else:
            cursor.execute("DELETE FROM financial_data")
            if cursor.rowcount > 0:
                logger.info(f"ğŸ—‘ï¸ æ¸…ç©ºäº†æ‰€æœ‰ç¼“å­˜è®°å½•ï¼Œå…± {cursor.rowcount} æ¡")

        deleted_count = cursor.rowcount
        conn.commit()
        return deleted_count

    def get_symbol_summary(self, symbol: str) -> Dict[str, Any]:
        """
        è·å–æŒ‡å®šè‚¡ç¥¨çš„ç¼“å­˜æ¦‚è¦

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            ç¼“å­˜æ¦‚è¦ä¿¡æ¯
        """
        conn = self._get_connection()
        cursor = conn.cursor()

        cursor.execute("""
            SELECT
                query_type,
                COUNT(*) as record_count,
                MIN(date_value) as earliest_date,
                MAX(date_value) as latest_date
            FROM financial_data
            WHERE symbol = ?
            GROUP BY query_type
            ORDER BY query_type
        """, (symbol,))

        summary = {}
        for row in cursor.fetchall():
            query_type, count, earliest, latest = row
            summary[query_type] = {
                'record_count': count,
                'date_range': f"{earliest} è‡³ {latest}" if earliest and latest else "æ— æ•°æ®"
            }

        return summary

    def close(self) -> None:
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if hasattr(self._local, 'connection'):
            self._local.connection.close()
            delattr(self._local, 'connection')